{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b2cb73a0bff6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pylab as plb\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_data(filename, num_images):\n",
    "#    with gzip.open(filename) as bytestream:\n",
    "#        bytestream.read(16)\n",
    "#        buf = bytestream.read(28 * 28 * num_images)\n",
    "#        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "#        data = data.reshape(num_images, 28,28)\n",
    "#        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\n",
    "# test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_labels(filename, num_images):\n",
    "#    with gzip.open(filename) as bytestream:\n",
    "#        bytestream.read(8)\n",
    "#        buf = bytestream.read(1 * num_images)\n",
    "#        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "#        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\n",
    "# test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shapes of training set\n",
    "# print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "\n",
    "## Shapes of test set\n",
    "# print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dictionary of target classes\n",
    "# label_dict = {\n",
    " # 0: 'A',\n",
    " # 1: 'B',\n",
    " # 2: 'C',\n",
    " # 3: 'D',\n",
    " # 4: 'E',\n",
    " # 5: 'F',\n",
    " # 6: 'G',\n",
    " # 7: 'H',\n",
    " # 8: 'I',\n",
    " # 9: 'J',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDir = os.getcwd()\n",
    "datasetDir = currentDir + \"\\\\FilteredImages\\\\\"\n",
    "# datasetDir = currentDir + \"/FilteredImages2/\" # NEW SINGLE IMAGES DIRECTORY\n",
    "trainDir = os.path.join(datasetDir, \"train\")\n",
    "testDir = os.path.join(datasetDir, \"test\")\n",
    "validDir = os.path.join(datasetDir, \"valid\")\n",
    "y_dataDir = os.path.join(datasetDir, \"y_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFirst(val):\n",
    "    return val[0]\n",
    "\n",
    "def getBinary(dataFile):\n",
    "    listOfTraining = []\n",
    "    trainingHeader = []\n",
    "    with open(dataFile) as csvfile:\n",
    "#     reader = csv.DictReader(csvfile)\n",
    "        reader2 = csv.reader(csvfile)\n",
    "        listOfTraining = list(reader2)\n",
    "        trainingHeader = listOfTraining[0]\n",
    "        listOfTraining.pop(0)\n",
    "#         listOfTraining = listOfTraining.sort(key = sortFirst, reverse = False)\n",
    "#         np.asarray(listofTraining, dtype=np.int32)\n",
    "#         return np.asarray(listofTraining, dtype=np.int32)\n",
    "    listOfTrainingBinary = []\n",
    "    for item in listOfTraining:\n",
    "        listOfTrainingBinary.append(item[1])\n",
    "    return np.asarray(listOfTrainingBinary, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "y_trainDir = os.path.join(y_dataDir, 'train_split_Depression_AVEC2017-edited.csv')\n",
    "# print(y_trainDir)\n",
    "y_train = getBinary(y_trainDir)\n",
    "y_testDir = os.path.join(y_dataDir, 'dev_split_Depression_AVEC2017.csv')\n",
    "# print(y_testDir)\n",
    "y_test = getBinary(y_testDir)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "\n",
    "# Y_train = np.asarray(y_train, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainDir = trainDir\n",
    "x_testDir = testDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSet = []\n",
    "# testFolders =[]\n",
    "# # trainingSet = []\n",
    "# trainingFolders = []\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "\n",
    "def getImagesDir(mainDirectory):\n",
    "    ImgDict = {}\n",
    "    ImgList = []\n",
    "    \n",
    "    for folder in os.listdir(mainDirectory):\n",
    "        theDir = os.path.join(mainDirectory, folder)\n",
    "        images = os.listdir(theDir)\n",
    "        listOfImgDir = []\n",
    "        for img in images:\n",
    "#             listOfImgDir.append(Image.open(os.path.join(theDir, img)))\n",
    "            listOfImgDir.append(os.path.join(theDir, img))\n",
    "#         print(listOfImgDir)\n",
    "#         print(images)\n",
    "        folderName = folder.split('_')\n",
    "        ImgDict[folderName[0]] = listOfImgDir\n",
    "        ImgList.append(listOfImgDir)\n",
    "    imgList = ImgList.sort(key = sortFirst, reverse = False)\n",
    "    return ImgList\n",
    "\n",
    "trainingImagesDir = getImagesDir(trainDir)\n",
    "testImagesDir = getImagesDir(testDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importImages(listOfImgDir):\n",
    "    myFolder = []\n",
    "    for folder in listOfImgDir:\n",
    "        myImages = []\n",
    "        for image in folder:\n",
    "            myImages.append(np.array(Image.open(image)))\n",
    "        myFolder.append(np.array(myImages))\n",
    "    return myFolder\n",
    "\n",
    "#First Array iterate through Folder, Second Array Iterate though Image in Folder\n",
    "trainingImages = importImages(trainingImagesDir)\n",
    "testImages = importImages(testImagesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num of Img, Height, Width\n",
    "print(len(trainingImages)) \n",
    "\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingImagesNP = np.array(trainingImages)\n",
    "testImagesNP = np.array(testImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=trainingImagesNP.shape))\n",
    "\n",
    "## Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=testImagesNP.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trainingImages.shape)\n",
    "# print(trainingImages[0])\n",
    "# print(trainingImagesNP[10].shape)\n",
    "# print(y_train)\n",
    "\n",
    "neg = []\n",
    "y_neg = []\n",
    "pos = []\n",
    "y_pos = []\n",
    "\n",
    "for x,y in zip(trainingImages, y_train):\n",
    "    if (y == 0):\n",
    "        for each in x:\n",
    "            neg.append(each)\n",
    "            y_neg.append(0)\n",
    "    else:\n",
    "        for each in x:\n",
    "            pos.append(each)\n",
    "            y_pos.append(1)\n",
    "\n",
    "X = pos + neg\n",
    "Y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test = []\n",
    "y_neg_test = []\n",
    "pos_test = []\n",
    "y_pos_test = []\n",
    "\n",
    "for x,y in zip(testImages, y_train):\n",
    "    if (y == 0):\n",
    "        for each in x:\n",
    "            neg_test.append(each)\n",
    "            y_neg_test.append(0)\n",
    "    else:\n",
    "        for each in x:\n",
    "            pos_test.append(each)\n",
    "            y_pos_test.append(1)\n",
    "\n",
    "X_test = pos_test + neg_test\n",
    "Y_test = y_pos_test + y_neg_test\n",
    "\n",
    "npX_test = np.array(X_test)\n",
    "npY_test = np.array(Y_test)\n",
    "newNPX_test = npX_test.reshape(npX_test.shape[0], 101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newNPX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vImagesDir = getImagesDir(validDir)\n",
    "vImages = importImages(vImagesDir)\n",
    "vImagesNP = np.array(vImages)\n",
    "\n",
    "#TESTING DATA UNSEEN DATA\n",
    "v = []\n",
    "# y_neg_v = []\n",
    "# pos_v = []\n",
    "# y_pos_v = []\n",
    "\n",
    "for x in vImages:\n",
    "    for each in x:\n",
    "        v.append(each)\n",
    "\n",
    "# X_v = pos_v + neg_v\n",
    "# Y_v = y_pos_v + y_neg_v\n",
    "\n",
    "np_v = np.array(v)\n",
    "# npY_test = np.array(Y_test)\n",
    "newNPX_v = np_v.reshape(np_v.shape[0], 101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newNPX_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npX = np.array(X)\n",
    "npY = np.array(Y)\n",
    "\n",
    "# print(npX)\n",
    "# print(npY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(npX.shape)\n",
    "print(npY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNPX = npX.reshape(npX.shape[0], 101, 1000, 1)\n",
    "print(newNPX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNPX = np.resize(newNPX, (npX.shape[0], 100, 1000, 1))\n",
    "print(newNPX.shape)\n",
    "newNPX_v = np.resize(newNPX_v, (np_v.shape[0], 100, 1000, 1))\n",
    "print(newNPX_v.shape)\n",
    "newNPX_test = np.resize(newNPX_test, (npX_test.shape[0], 100, 1000, 1))\n",
    "print(newNPX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[5,5])\n",
    "\n",
    "## Display the first image in training data\n",
    "# plt.subplot(121)\n",
    "# curr_img = np.reshape(train_data[0], (28,28))\n",
    "# curr_lbl = train_labels[0]\n",
    "# plt.imshow(curr_img, cmap='gray')\n",
    "# plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "## Display the first image in testing data\n",
    "# plt.subplot(122)\n",
    "# curr_img = np.reshape(test_data[0], (28,28))\n",
    "# curr_lbl = test_labels[0]\n",
    "# plt.imshow(curr_img, cmap='gray')\n",
    "# plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[75, 75])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = npX[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np_v[0]\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.reshape(-1, 28,28, 1)\n",
    "# test_data = test_data.reshape(-1, 28,28, 1)\n",
    "# train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data / np.max(train_data)\n",
    "# test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "#                                                             train_data, \n",
    "#                                                             test_size=0.2, \n",
    "#                                                             random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# epochs = 50\n",
    "# inChannel = 1\n",
    "# x, y = 28, 28\n",
    "# input_img = Input(shape = (x, y, inChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "numEpochs = 50\n",
    "model_path = os.path.join(currentDir,'AutoencoderTest'+ str(numEpochs) + '.h5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='acc', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [checkpoint, tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.1\n",
    "x_train_noisy = newNPX + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=newNPX.shape)\n",
    "x_valid_noisy = newNPX_v + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=newNPX_v.shape)\n",
    "x_test_noisy = newNPX_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=newNPX_test.shape)\n",
    "# x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "# x_valid_noisy = np.clip(x_valid_noisy, 0., 1.)\n",
    "# x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_valid_noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[75,75])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "#x_train_noisy = npX + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=npX.shape)\n",
    "curr_img = x_train_noisy[1] \n",
    "curr_img = np.reshape(x_train_noisy[1], (100,1000))\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "#x_test_noisy = npX_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=npX_test.shape)\n",
    "curr_img = x_test_noisy[1]\n",
    "curr_img = np.reshape(x_test_noisy[1], (100,1000))\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 20\n",
    "# inChannel = 1\n",
    "# x, y = 28, 28\n",
    "# input_img = Input(shape = (x, y, inChannel))\n",
    "\n",
    "input_img = Input(shape = (100, 1000, 1))\n",
    "\n",
    "np.max(newNPX), np.max(newNPX_test), np.max(newNPX_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(input_img):\n",
    "    #encoder\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv6)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv7)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "    #decoder\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    up1 = UpSampling2D((2,2))(conv9)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    up2 = UpSampling2D((2,2))(conv10)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, autoencoder(input_img))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop(), metrics=['accuracy'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_noisy.shape)\n",
    "print(newNPX.shape)\n",
    "print(newNPX_test.shape)\n",
    "print(npY.shape)\n",
    "print(npY_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train = autoencoder.fit(x=x_train_noisy, y=newNPX, batch_size=batch_size,epochs=epochs,validation_data=(x_test_noisy, newNPX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = autoencoder_train.history['acc']\n",
    "val_acc = autoencoder_train.history['val_acc']\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(newNPX_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "print(\"Test Images\")\n",
    "for i in range(10,20,1):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(newNPX_v[i, ..., 0], cmap='gray')\n",
    "    curr_lbl = npY_test[i]\n",
    "    #plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "plt.show()    \n",
    "plt.figure(figsize=(20, 4))\n",
    "print(\"Test Images with Noise\")\n",
    "for i in range(10,20,1):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(x_test_noisy[i, ..., 0], cmap='gray')\n",
    "plt.show()    \n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "print(\"Reconstruction of Noisy Test Images\")\n",
    "for i in range(10,20,1):\n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.imshow(pred[i, ..., 0], cmap='gray')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy: \", np.mean(autoencoder_train.history['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_folds = 5\n",
    "# count = 0\n",
    "# for _ in range(n_folds):\n",
    "#     # split data\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(newNPX, npY, test_size=0.10, random_state = np.random.randint(1,1000, 1)[0])\n",
    "#     # evaluate model\n",
    "#     autoencoder_kfold = autoencoder.fit(x=X_train, y=y_train, batch_size=batch_size,epochs=20,validation_data=(X_val, y_val))\n",
    "#     count += 1\n",
    "#     print('K-Fold has ran ', count, ' time(s)')\n",
    "    \n",
    "# print('\\nModel Accuracy after all K-Fold: ', (np.mean(autoencoder_kfold.history['acc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "test_ae = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNPX = npX.reshape(npX.shape[0], 101, 1000, 1)\n",
    "print(newNPX.shape)\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = newNPX + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=newNPX.shape)\n",
    "predictor = test_ae.predict(x_test_noisy, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[75, 75])\n",
    "\n",
    "plt.subplot(121)\n",
    "curr_img = predictor[2]\n",
    "curr_img = np.reshape(predictor[2], (100,1000))\n",
    "plt.imshow(curr_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
