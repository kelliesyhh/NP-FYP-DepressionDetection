{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plb\n",
    "# import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4482970525919741599\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4945621811\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5193168271277820073\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\" #for GPU Support on MacBook\n",
    "print(tf.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDir = os.getcwd()\n",
    "datasetDir = currentDir + \"\\\\FilteredImages\\\\\"\n",
    "# datasetDir = currentDir + \"/FilteredImages2/\" # NEW SINGLE IMAGES DIRECTORY\n",
    "trainDir = os.path.join(datasetDir, \"train\")\n",
    "testDir = os.path.join(datasetDir, \"test\")\n",
    "validDir = os.path.join(datasetDir, \"valid\")\n",
    "y_dataDir = os.path.join(datasetDir, \"y_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFirst(val):\n",
    "    return val[0]\n",
    "\n",
    "def getBinary(dataFile):\n",
    "    listOfTraining = []\n",
    "    trainingHeader = []\n",
    "    with open(dataFile) as csvfile:\n",
    "#     reader = csv.DictReader(csvfile)\n",
    "        reader2 = csv.reader(csvfile)\n",
    "        listOfTraining = list(reader2)\n",
    "        trainingHeader = listOfTraining[0]\n",
    "        listOfTraining.pop(0)\n",
    "#         listOfTraining = listOfTraining.sort(key = sortFirst, reverse = False)\n",
    "#         np.asarray(listofTraining, dtype=np.int32)\n",
    "#         return np.asarray(listofTraining, dtype=np.int32)\n",
    "    listOfTrainingBinary = []\n",
    "    for item in listOfTraining:\n",
    "        listOfTrainingBinary.append(item[1])\n",
    "    return np.asarray(listOfTrainingBinary, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "y_trainDir = os.path.join(y_dataDir, 'train_split_Depression_AVEC2017-edited.csv')\n",
    "# print(y_trainDir)\n",
    "y_train = getBinary(y_trainDir)\n",
    "y_testDir = os.path.join(y_dataDir, 'dev_split_Depression_AVEC2017.csv')\n",
    "# print(y_testDir)\n",
    "y_test = getBinary(y_testDir)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "\n",
    "# Y_train = np.asarray(y_train, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainDir = trainDir\n",
    "x_testDir = testDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tanho\\\\Downloads\\\\Aaron-Workspace\\\\FilteredImages\\\\train'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trainDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSet = []\n",
    "# testFolders =[]\n",
    "# # trainingSet = []\n",
    "# trainingFolders = []\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "\n",
    "def getImagesDir(mainDirectory):\n",
    "    ImgDict = {}\n",
    "    ImgList = []\n",
    "    \n",
    "    for folder in os.listdir(mainDirectory):\n",
    "        theDir = os.path.join(mainDirectory, folder)\n",
    "        images = os.listdir(theDir)\n",
    "        listOfImgDir = []\n",
    "        for img in images:\n",
    "#             listOfImgDir.append(Image.open(os.path.join(theDir, img)))\n",
    "            listOfImgDir.append(os.path.join(theDir, img))\n",
    "#         print(listOfImgDir)\n",
    "#         print(images)\n",
    "        folderName = folder.split('_')\n",
    "        ImgDict[folderName[0]] = listOfImgDir\n",
    "        ImgList.append(listOfImgDir)\n",
    "    imgList = ImgList.sort(key = sortFirst, reverse = False)\n",
    "    return ImgList\n",
    "        \n",
    "        \n",
    "#         for img in images\n",
    "    \n",
    "# for folder in toProcessList:\n",
    "#     images = os.listdir(datasetDir + \"/\" + folder)\n",
    "#     folderName = folder.split('_')\n",
    "# #     print(folderName[0])\n",
    "#     if folderName[0] in listOfTrainingName:\n",
    "#         trainingFolders.append(datasetDir + \"/\" + folder)\n",
    "# #         print(folderName)\n",
    "#         index = listOfTrainingName.index(folderName[0])\n",
    "#         temp = listOfTraining[index]\n",
    "#         x_train.append(images)\n",
    "#         tempBList = []\n",
    "#         val = temp[1]\n",
    "#         tempBList.append(val)\n",
    "#         y_train.append(tempBList)\n",
    "#         #temp.append(images)\n",
    "#         #trainingSet.append(temp)\n",
    "#     else:\n",
    "#         testFolders.append(datasetDir + \"/\" + folder)\n",
    "#         testSet.append(images)\n",
    "\n",
    "trainingImagesDir = getImagesDir(trainDir)\n",
    "testImagesDir = getImagesDir(testDir)\n",
    "# np.array(trainingImages).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importImages(listOfImgDir):\n",
    "    myFolder = []\n",
    "    for folder in listOfImgDir:\n",
    "        myImages = []\n",
    "        for image in folder:\n",
    "            myImages.append(np.array(Image.open(image)))\n",
    "        myFolder.append(np.array(myImages))\n",
    "    return myFolder\n",
    "\n",
    "\n",
    "#First Array iterate through Folder, Second Array Iterate though Image in Folder\n",
    "trainingImages = importImages(trainingImagesDir)\n",
    "testImages = importImages(testImagesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Num of Img, Height, Width\n",
    "print(len(trainingImages)) \n",
    "\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingImagesNP = np.array(trainingImages)\n",
    "testImagesNP = np.array(testImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trainingImages.shape)\n",
    "# print(trainingImages[0])\n",
    "# print(trainingImagesNP[10].shape)\n",
    "# print(y_train)\n",
    "\n",
    "neg = []\n",
    "y_neg = []\n",
    "pos = []\n",
    "y_pos = []\n",
    "\n",
    "for x,y in zip(trainingImages, y_train):\n",
    "    if (y == 0):\n",
    "        for each in x:\n",
    "            neg.append(each)\n",
    "            y_neg.append(0)\n",
    "    else:\n",
    "        for each in x:\n",
    "            pos.append(each)\n",
    "            y_pos.append(1)\n",
    "\n",
    "X = pos + neg\n",
    "Y = y_pos + y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test = []\n",
    "y_neg_test = []\n",
    "pos_test = []\n",
    "y_pos_test = []\n",
    "\n",
    "for x,y in zip(testImages, y_train):\n",
    "    if (y == 0):\n",
    "        for each in x:\n",
    "            neg_test.append(each)\n",
    "            y_neg_test.append(0)\n",
    "    else:\n",
    "        for each in x:\n",
    "            pos_test.append(each)\n",
    "            y_pos_test.append(1)\n",
    "\n",
    "X_test = pos_test + neg_test\n",
    "Y_test = y_pos_test + y_neg_test\n",
    "\n",
    "\n",
    "npX_test = np.array(X_test)\n",
    "npY_test = np.array(Y_test)\n",
    "newNPX_test = npX_test.reshape(npX_test.shape[0], 101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vImagesDir = getImagesDir(validDir)\n",
    "vImages = importImages(vImagesDir)\n",
    "vImagesNP = np.array(vImages)\n",
    "\n",
    "#TESTING DATA UNSEEN DATA\n",
    "v = []\n",
    "# y_neg_v = []\n",
    "# pos_v = []\n",
    "# y_pos_v = []\n",
    "\n",
    "for x in vImages:\n",
    "    for each in x:\n",
    "        v.append(each)\n",
    "\n",
    "# X_v = pos_v + neg_v\n",
    "# Y_v = y_pos_v + y_neg_v\n",
    "\n",
    "\n",
    "np_v = np.array(v)\n",
    "# npY_test = np.array(Y_test)\n",
    "newNPX_v = np_v.reshape(np_v.shape[0], 101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "npX = np.array(X)\n",
    "npY = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4591, 101, 1000)\n",
      "(4591,)\n"
     ]
    }
   ],
   "source": [
    "print(npX.shape)\n",
    "print(npY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNPX = npX.reshape(npX.shape[0], 101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4591, 101, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(newNPX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trainingImagesNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (101, 1000, 3)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#numEpochs = 100\n",
    "numEpochs = 30\n",
    "model_path = os.path.join(currentDir,'DAM-DHM-V-'+ str(numEpochs) +'.h5')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(model_path, monitor='loss', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# checkpoint = ModelCheckpoint(model_path, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='acc', verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
    "tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [checkpoint, tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (101, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR HARRY\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def evaluate_model(X_train, X_val, y_train, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(4, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(4, 3)))\n",
    "\n",
    "    model.add(Conv2D(96, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(4, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adadelta', #adam\n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "    print(model.metrics_names)\n",
    "    \n",
    "    model.save_weights('model.h5')\n",
    "    \n",
    "    callbacks = [EarlyStopping(monitor='val_acc', patience = 10)]\n",
    "    \n",
    "    hist=model.fit(x=X_train, y=y_train, batch_size=32, epochs=numEpochs, callbacks=callbacks_list, validation_data=(X_val, y_val))\n",
    "    \n",
    "    _, val_acc=model.evaluate(x=X_val, y=y_val, verbose=1)\n",
    "  \n",
    "    model.load_weights('model.h5')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    print(\"acc: \", np.mean(hist.history['acc']))\n",
    "    \n",
    "    print(\"val_acc: \", val_acc)\n",
    "    \n",
    "    model.save(''+ str(numEpochs) +' Epoch (Dr Harry Model) w validation.h5')\n",
    "    \n",
    "    return model, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tanho\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "['loss', 'acc']\n",
      "WARNING:tensorflow:From C:\\Users\\tanho\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4591 samples, validate on 1740 samples\n",
      "Epoch 1/30\n",
      "4591/4591 [==============================] - 40s 9ms/step - loss: 0.6199 - acc: 0.7136 - val_loss: 0.8270 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5999 - acc: 0.7188 - val_loss: 0.7076 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5951 - acc: 0.7188 - val_loss: 0.7179 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5957 - acc: 0.7188 - val_loss: 0.7425 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5946 - acc: 0.7192 - val_loss: 0.7063 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.6011 - acc: 0.7188 - val_loss: 0.7267 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5949 - acc: 0.7188 - val_loss: 0.7168 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5949 - acc: 0.7188 - val_loss: 0.7157 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5950 - acc: 0.7188 - val_loss: 0.7099 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5968 - acc: 0.7188 - val_loss: 0.7175 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5948 - acc: 0.7188 - val_loss: 0.7257 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5958 - acc: 0.7155 - val_loss: 0.7115 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5947 - acc: 0.7188 - val_loss: 0.7239 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5944 - acc: 0.7188 - val_loss: 0.7065 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5903 - acc: 0.7188 - val_loss: 0.7143 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5864 - acc: 0.7151 - val_loss: 0.7088 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5767 - acc: 0.7210 - val_loss: 0.7315 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5653 - acc: 0.7247 - val_loss: 0.7623 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5500 - acc: 0.7323 - val_loss: 0.7102 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5403 - acc: 0.7351 - val_loss: 0.7643 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.5175 - acc: 0.7545 - val_loss: 0.7769 - val_acc: 0.5316\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.4753 - acc: 0.7863 - val_loss: 0.9025 - val_acc: 0.5690\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.4078 - acc: 0.8220 - val_loss: 0.8585 - val_acc: 0.5557\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.2934 - acc: 0.8780 - val_loss: 1.5519 - val_acc: 0.5776\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.1402 - acc: 0.9486 - val_loss: 1.6880 - val_acc: 0.5483\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.0548 - acc: 0.9791 - val_loss: 2.0401 - val_acc: 0.5397\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.0249 - acc: 0.9917 - val_loss: 2.7441 - val_acc: 0.5471\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.0155 - acc: 0.9954 - val_loss: 3.6092 - val_acc: 0.5632\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.0161 - acc: 0.9959 - val_loss: 3.3631 - val_acc: 0.5569\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4591/4591 [==============================] - 35s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 3.8529 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "1740/1740 [==============================] - 4s 3ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.7851085457449635\n",
      "val_acc:  0.5511494252873563\n"
     ]
    }
   ],
   "source": [
    "# run CNN model\n",
    "model, val_acc = evaluate_model(newNPX, newNPX_test, npY, npY_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 30s 7ms/step - loss: 4.1850 - acc: 0.7139 - val_loss: 0.6859 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.6081 - acc: 0.7240 - val_loss: 0.6400 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5932 - acc: 0.7240 - val_loss: 0.6680 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5928 - acc: 0.7206 - val_loss: 0.6394 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5889 - acc: 0.7240 - val_loss: 0.6512 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5922 - acc: 0.7240 - val_loss: 0.6308 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5812 - acc: 0.7240 - val_loss: 0.7153 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5725 - acc: 0.7219 - val_loss: 0.6041 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5630 - acc: 0.7262 - val_loss: 0.5939 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5450 - acc: 0.7386 - val_loss: 0.6396 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5489 - acc: 0.7376 - val_loss: 0.5906 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5316 - acc: 0.7475 - val_loss: 0.7201 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5182 - acc: 0.7582 - val_loss: 0.6122 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5017 - acc: 0.7652 - val_loss: 0.6129 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.4889 - acc: 0.7771 - val_loss: 0.5532 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.4599 - acc: 0.7894 - val_loss: 0.6285 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.4134 - acc: 0.8226 - val_loss: 1.3734 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.3487 - acc: 0.8552 - val_loss: 0.6177 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.2718 - acc: 0.8918 - val_loss: 1.0198 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.1864 - acc: 0.9298 - val_loss: 1.1557 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0998 - acc: 0.9642 - val_loss: 1.5369 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0483 - acc: 0.9855 - val_loss: 1.7053 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0379 - acc: 0.9896 - val_loss: 1.7834 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0322 - acc: 0.9920 - val_loss: 2.1637 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0317 - acc: 0.9920 - val_loss: 2.1251 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 2.5422 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0180 - acc: 0.9952 - val_loss: 3.3138 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 2.6984 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.0306 - acc: 0.9956 - val_loss: 2.7045 - val_acc: 0.6304\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0744 - acc: 0.9838 - val_loss: 2.2313 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 3ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8403857016095927\n",
      "val_acc:  0.6760869570400404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.6442 - acc: 0.7105 - val_loss: 0.6227 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.6053 - acc: 0.7197 - val_loss: 0.6011 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5962 - acc: 0.7197 - val_loss: 0.6017 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5955 - acc: 0.7197 - val_loss: 0.6007 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5942 - acc: 0.7197 - val_loss: 0.6028 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5931 - acc: 0.7197 - val_loss: 0.5957 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5857 - acc: 0.7153 - val_loss: 0.6549 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5750 - acc: 0.7206 - val_loss: 0.7229 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5703 - acc: 0.7204 - val_loss: 0.7593 - val_acc: 0.3152\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 29s 7ms/step - loss: 0.5500 - acc: 0.7243 - val_loss: 0.9171 - val_acc: 0.2891\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5398 - acc: 0.7393 - val_loss: 1.1425 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5220 - acc: 0.7570 - val_loss: 0.7333 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5080 - acc: 0.7657 - val_loss: 0.6000 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4923 - acc: 0.7727 - val_loss: 0.5952 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4831 - acc: 0.7877 - val_loss: 0.5460 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4503 - acc: 0.7986 - val_loss: 0.5107 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4225 - acc: 0.8122 - val_loss: 0.6137 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4027 - acc: 0.8303 - val_loss: 0.5180 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3699 - acc: 0.8378 - val_loss: 0.7171 - val_acc: 0.7587\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3343 - acc: 0.8642 - val_loss: 0.5691 - val_acc: 0.7413\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2658 - acc: 0.8894 - val_loss: 0.5701 - val_acc: 0.7565\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2086 - acc: 0.9225 - val_loss: 0.6506 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1371 - acc: 0.9530 - val_loss: 1.0090 - val_acc: 0.6565\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1012 - acc: 0.9618 - val_loss: 0.9180 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0500 - acc: 0.9840 - val_loss: 1.1590 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0445 - acc: 0.9879 - val_loss: 1.2125 - val_acc: 0.7674\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0140 - acc: 0.9954 - val_loss: 1.4586 - val_acc: 0.7587\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0481 - acc: 0.9843 - val_loss: 1.1562 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0195 - acc: 0.9954 - val_loss: 1.2302 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 2.0037 - val_acc: 0.7609\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.827612361821243\n",
      "val_acc:  0.7608695646990901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6368 - acc: 0.7112 - val_loss: 0.9010 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5968 - acc: 0.7211 - val_loss: 0.6209 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5949 - acc: 0.7211 - val_loss: 0.6130 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5963 - acc: 0.7211 - val_loss: 0.6203 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5929 - acc: 0.7211 - val_loss: 0.6127 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5930 - acc: 0.7211 - val_loss: 0.6280 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5931 - acc: 0.7211 - val_loss: 0.6131 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5905 - acc: 0.7214 - val_loss: 4.8071 - val_acc: 0.3065\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6186 - acc: 0.7160 - val_loss: 0.5997 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5781 - acc: 0.7199 - val_loss: 0.6080 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5783 - acc: 0.7180 - val_loss: 0.5935 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5759 - acc: 0.7153 - val_loss: 0.5907 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5720 - acc: 0.7192 - val_loss: 0.5834 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5656 - acc: 0.7216 - val_loss: 0.6055 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5586 - acc: 0.7274 - val_loss: 0.5808 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5538 - acc: 0.7390 - val_loss: 0.5870 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5359 - acc: 0.7509 - val_loss: 0.7121 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5221 - acc: 0.7572 - val_loss: 0.6709 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4995 - acc: 0.7717 - val_loss: 0.5301 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4639 - acc: 0.7945 - val_loss: 0.7820 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4333 - acc: 0.8109 - val_loss: 0.6237 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3671 - acc: 0.8439 - val_loss: 0.7842 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3070 - acc: 0.8785 - val_loss: 0.7816 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2825 - acc: 0.8891 - val_loss: 0.6810 - val_acc: 0.7370\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1920 - acc: 0.9237 - val_loss: 0.8421 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1609 - acc: 0.9455 - val_loss: 0.9804 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1191 - acc: 0.9584 - val_loss: 1.3094 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0839 - acc: 0.9729 - val_loss: 1.3448 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0441 - acc: 0.9855 - val_loss: 1.7297 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0573 - acc: 0.9867 - val_loss: 1.8700 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_11 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_12 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.793512466720131\n",
      "val_acc:  0.7130434782608696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6302 - acc: 0.7160 - val_loss: 0.6285 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5989 - acc: 0.7194 - val_loss: 0.6071 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5985 - acc: 0.7194 - val_loss: 0.6109 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5968 - acc: 0.7194 - val_loss: 0.6002 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5943 - acc: 0.7158 - val_loss: 0.6188 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5886 - acc: 0.7192 - val_loss: 0.5998 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5793 - acc: 0.7187 - val_loss: 0.6149 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5745 - acc: 0.7168 - val_loss: 0.6427 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5740 - acc: 0.7209 - val_loss: 0.5816 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5641 - acc: 0.7267 - val_loss: 0.6280 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5592 - acc: 0.7369 - val_loss: 0.6371 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5485 - acc: 0.7449 - val_loss: 0.6328 - val_acc: 0.6239\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5423 - acc: 0.7458 - val_loss: 0.6102 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5245 - acc: 0.7613 - val_loss: 0.7675 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4998 - acc: 0.7785 - val_loss: 0.5907 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4773 - acc: 0.7896 - val_loss: 0.6663 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4458 - acc: 0.8061 - val_loss: 0.6309 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3978 - acc: 0.8344 - val_loss: 0.6734 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3420 - acc: 0.8625 - val_loss: 0.7682 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2840 - acc: 0.8811 - val_loss: 0.8497 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2121 - acc: 0.9145 - val_loss: 1.1676 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1688 - acc: 0.9339 - val_loss: 1.7831 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1260 - acc: 0.9579 - val_loss: 1.4517 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0619 - acc: 0.9770 - val_loss: 1.6367 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1076 - acc: 0.9753 - val_loss: 1.9197 - val_acc: 0.6957\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0946 - acc: 0.9772 - val_loss: 1.8729 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0485 - acc: 0.9881 - val_loss: 1.3043 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0438 - acc: 0.9889 - val_loss: 1.9424 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0420 - acc: 0.9864 - val_loss: 1.8284 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0192 - acc: 0.9932 - val_loss: 2.2661 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8275397401807153\n",
      "val_acc:  0.7130434787791708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.9047 - acc: 0.7146 - val_loss: 0.6063 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5983 - acc: 0.7204 - val_loss: 0.6144 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5946 - acc: 0.7204 - val_loss: 0.6108 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5941 - acc: 0.7204 - val_loss: 0.6073 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6067 - acc: 0.7204 - val_loss: 0.6770 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5884 - acc: 0.7209 - val_loss: 0.6116 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5822 - acc: 0.7160 - val_loss: 0.6295 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5764 - acc: 0.7185 - val_loss: 0.7713 - val_acc: 0.4130\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5805 - acc: 0.7168 - val_loss: 0.5939 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5716 - acc: 0.7199 - val_loss: 0.5866 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5639 - acc: 0.7269 - val_loss: 0.6146 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5574 - acc: 0.7337 - val_loss: 0.6215 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5478 - acc: 0.7456 - val_loss: 0.6532 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5295 - acc: 0.7514 - val_loss: 0.6758 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5201 - acc: 0.7579 - val_loss: 0.7006 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5038 - acc: 0.7708 - val_loss: 0.6135 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4800 - acc: 0.7790 - val_loss: 0.5844 - val_acc: 0.7217\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4432 - acc: 0.7974 - val_loss: 0.6214 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3974 - acc: 0.8284 - val_loss: 0.7001 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3069 - acc: 0.8746 - val_loss: 0.9327 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2087 - acc: 0.9145 - val_loss: 0.8799 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1157 - acc: 0.9588 - val_loss: 1.3590 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0602 - acc: 0.9806 - val_loss: 1.9373 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0486 - acc: 0.9860 - val_loss: 1.8394 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0169 - acc: 0.9944 - val_loss: 2.2074 - val_acc: 0.6413\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 2.4321 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0391 - acc: 0.9889 - val_loss: 1.9727 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0095 - acc: 0.9973 - val_loss: 2.2280 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0034 - acc: 0.9993 - val_loss: 2.6370 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0142 - acc: 0.9959 - val_loss: 2.4195 - val_acc: 0.6348\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_17 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8255386105112213\n",
      "val_acc:  0.6347826086956522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.7312 - acc: 0.7107 - val_loss: 0.7293 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5969 - acc: 0.7209 - val_loss: 0.7057 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5949 - acc: 0.7209 - val_loss: 0.6160 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5953 - acc: 0.7209 - val_loss: 0.6194 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5960 - acc: 0.7209 - val_loss: 0.6108 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5942 - acc: 0.7209 - val_loss: 0.6112 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5930 - acc: 0.7209 - val_loss: 0.6143 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5918 - acc: 0.7209 - val_loss: 0.6073 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5836 - acc: 0.7214 - val_loss: 0.5933 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5780 - acc: 0.7204 - val_loss: 0.5881 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5751 - acc: 0.7221 - val_loss: 0.5853 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5733 - acc: 0.7194 - val_loss: 0.5823 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5656 - acc: 0.7320 - val_loss: 0.6049 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5570 - acc: 0.7374 - val_loss: 0.5897 - val_acc: 0.7087\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5469 - acc: 0.7480 - val_loss: 0.6089 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5297 - acc: 0.7613 - val_loss: 0.6104 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5006 - acc: 0.7812 - val_loss: 0.6714 - val_acc: 0.6674\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4482 - acc: 0.8092 - val_loss: 0.8918 - val_acc: 0.6957\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3918 - acc: 0.8349 - val_loss: 0.8999 - val_acc: 0.6087\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3330 - acc: 0.8591 - val_loss: 1.2113 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2861 - acc: 0.8765 - val_loss: 1.4575 - val_acc: 0.6957\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2514 - acc: 0.8940 - val_loss: 1.8107 - val_acc: 0.6304\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2139 - acc: 0.9126 - val_loss: 1.8684 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1770 - acc: 0.9322 - val_loss: 1.7909 - val_acc: 0.6630\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1072 - acc: 0.9569 - val_loss: 2.5739 - val_acc: 0.6348\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0895 - acc: 0.9678 - val_loss: 2.7324 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0417 - acc: 0.9855 - val_loss: 3.0863 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0867 - acc: 0.9804 - val_loss: 3.5052 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0427 - acc: 0.9889 - val_loss: 2.9041 - val_acc: 0.6370\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0390 - acc: 0.9898 - val_loss: 2.9154 - val_acc: 0.6261\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_21 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8129347212205621\n",
      "val_acc:  0.6260869560034379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6617 - acc: 0.7182 - val_loss: 0.5946 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5997 - acc: 0.7187 - val_loss: 0.5945 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6223 - acc: 0.7187 - val_loss: 0.5931 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5963 - acc: 0.7187 - val_loss: 0.5947 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5959 - acc: 0.7187 - val_loss: 0.6013 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5968 - acc: 0.7187 - val_loss: 0.5940 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5950 - acc: 0.7187 - val_loss: 0.6021 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5956 - acc: 0.7187 - val_loss: 0.5929 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5947 - acc: 0.7187 - val_loss: 0.5933 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5946 - acc: 0.7187 - val_loss: 0.5933 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5942 - acc: 0.7187 - val_loss: 0.6015 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6050 - acc: 0.7187 - val_loss: 0.6052 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5857 - acc: 0.7185 - val_loss: 0.5869 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5807 - acc: 0.7175 - val_loss: 0.5945 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5756 - acc: 0.7190 - val_loss: 0.5841 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5740 - acc: 0.7153 - val_loss: 0.6014 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5591 - acc: 0.7323 - val_loss: 0.5928 - val_acc: 0.7217\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5508 - acc: 0.7383 - val_loss: 0.6908 - val_acc: 0.6065\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5389 - acc: 0.7470 - val_loss: 0.7124 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5287 - acc: 0.7528 - val_loss: 0.5671 - val_acc: 0.7283\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5126 - acc: 0.7722 - val_loss: 0.5746 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4872 - acc: 0.7749 - val_loss: 1.2466 - val_acc: 0.4348\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4599 - acc: 0.8000 - val_loss: 0.6327 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4013 - acc: 0.8235 - val_loss: 0.6638 - val_acc: 0.6674\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2884 - acc: 0.8819 - val_loss: 0.8601 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1957 - acc: 0.9250 - val_loss: 1.0812 - val_acc: 0.7239\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1134 - acc: 0.9579 - val_loss: 1.2411 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0718 - acc: 0.9772 - val_loss: 1.3929 - val_acc: 0.7087\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0319 - acc: 0.9918 - val_loss: 1.6216 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0191 - acc: 0.9954 - val_loss: 1.9034 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_23 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_24 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.7788186879755076\n",
      "val_acc:  0.7152173907860465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6443 - acc: 0.7088 - val_loss: 0.5869 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6062 - acc: 0.7151 - val_loss: 0.5713 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6003 - acc: 0.7151 - val_loss: 0.5694 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6005 - acc: 0.7151 - val_loss: 0.5674 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5996 - acc: 0.7151 - val_loss: 0.5623 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6100 - acc: 0.7151 - val_loss: 0.5706 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5983 - acc: 0.7151 - val_loss: 0.5681 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5982 - acc: 0.7151 - val_loss: 0.5761 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6032 - acc: 0.7131 - val_loss: 0.5602 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5959 - acc: 0.7151 - val_loss: 0.5587 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5878 - acc: 0.7151 - val_loss: 0.5576 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5625 - acc: 0.7139 - val_loss: 0.6737 - val_acc: 0.5065\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5515 - acc: 0.7211 - val_loss: 0.5126 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5362 - acc: 0.7434 - val_loss: 0.5908 - val_acc: 0.6196\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5204 - acc: 0.7478 - val_loss: 0.4902 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5105 - acc: 0.7606 - val_loss: 0.8907 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4989 - acc: 0.7633 - val_loss: 1.0032 - val_acc: 0.4435\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4801 - acc: 0.7783 - val_loss: 0.8270 - val_acc: 0.5239\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4555 - acc: 0.7945 - val_loss: 0.6023 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4437 - acc: 0.8030 - val_loss: 0.4514 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4212 - acc: 0.8155 - val_loss: 0.4637 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4118 - acc: 0.8260 - val_loss: 0.5406 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3739 - acc: 0.8383 - val_loss: 0.3534 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3732 - acc: 0.8422 - val_loss: 0.4442 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3503 - acc: 0.8477 - val_loss: 0.4020 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3178 - acc: 0.8664 - val_loss: 0.3059 - val_acc: 0.8761\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3004 - acc: 0.8775 - val_loss: 0.3818 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2756 - acc: 0.8831 - val_loss: 0.7100 - val_acc: 0.5152\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2356 - acc: 0.9053 - val_loss: 0.5949 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2346 - acc: 0.9020 - val_loss: 0.3756 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_25 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_26 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_27 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.7762446542479924\n",
      "val_acc:  0.8586956526922143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6291 - acc: 0.7122 - val_loss: 1.0347 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6001 - acc: 0.7209 - val_loss: 0.6175 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6017 - acc: 0.7209 - val_loss: 0.6104 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5944 - acc: 0.7199 - val_loss: 0.6126 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5928 - acc: 0.7209 - val_loss: 0.6114 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5932 - acc: 0.7209 - val_loss: 0.6115 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5912 - acc: 0.7209 - val_loss: 0.6105 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6007 - acc: 0.7206 - val_loss: 0.5996 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5646 - acc: 0.7197 - val_loss: 0.5742 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5439 - acc: 0.7252 - val_loss: 0.5686 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5288 - acc: 0.7417 - val_loss: 0.7680 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5176 - acc: 0.7446 - val_loss: 0.5534 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4953 - acc: 0.7710 - val_loss: 0.4473 - val_acc: 0.7891\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4787 - acc: 0.7787 - val_loss: 0.5826 - val_acc: 0.7543\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4706 - acc: 0.7867 - val_loss: 0.8395 - val_acc: 0.4826\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4460 - acc: 0.8066 - val_loss: 0.4242 - val_acc: 0.7913\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4427 - acc: 0.8022 - val_loss: 0.9458 - val_acc: 0.3457\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4224 - acc: 0.8192 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4033 - acc: 0.8247 - val_loss: 0.4086 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3904 - acc: 0.8330 - val_loss: 0.5111 - val_acc: 0.7609\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3582 - acc: 0.8487 - val_loss: 0.4421 - val_acc: 0.8087\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3370 - acc: 0.8550 - val_loss: 0.4090 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3279 - acc: 0.8656 - val_loss: 0.3023 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2845 - acc: 0.8807 - val_loss: 0.3283 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2612 - acc: 0.8891 - val_loss: 0.8854 - val_acc: 0.6587\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2302 - acc: 0.9066 - val_loss: 0.6586 - val_acc: 0.7326\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2011 - acc: 0.9177 - val_loss: 0.3877 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1678 - acc: 0.9320 - val_loss: 0.5463 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1198 - acc: 0.9601 - val_loss: 0.4128 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1019 - acc: 0.9620 - val_loss: 2.9028 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_28 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_29 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_30 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8042685386976894\n",
      "val_acc:  0.7065217391304348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Train on 4131 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6406 - acc: 0.7134 - val_loss: 0.6301 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00001: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 2/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6012 - acc: 0.7211 - val_loss: 0.6141 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00002: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 3/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.6046 - acc: 0.7211 - val_loss: 0.6126 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00003: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 4/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5939 - acc: 0.7211 - val_loss: 0.6124 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00004: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 5/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5933 - acc: 0.7211 - val_loss: 0.6163 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00005: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 6/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5971 - acc: 0.7211 - val_loss: 0.6127 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00006: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 7/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5932 - acc: 0.7202 - val_loss: 0.6173 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00007: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 8/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5933 - acc: 0.7211 - val_loss: 0.6133 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00008: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 9/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5929 - acc: 0.7211 - val_loss: 0.6194 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00009: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 10/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5915 - acc: 0.7211 - val_loss: 0.6095 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00010: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 11/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5890 - acc: 0.7211 - val_loss: 0.6080 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00011: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 12/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5843 - acc: 0.7221 - val_loss: 0.7077 - val_acc: 0.4413\n",
      "\n",
      "Epoch 00012: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 13/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5786 - acc: 0.7190 - val_loss: 0.6653 - val_acc: 0.5630\n",
      "\n",
      "Epoch 00013: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 14/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5809 - acc: 0.7199 - val_loss: 0.6261 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00014: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 15/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5653 - acc: 0.7221 - val_loss: 0.6456 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00015: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 16/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5511 - acc: 0.7272 - val_loss: 0.5874 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00016: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 17/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.5253 - acc: 0.7468 - val_loss: 0.7152 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00017: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 18/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4904 - acc: 0.7645 - val_loss: 0.5992 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00018: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 19/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.4191 - acc: 0.8122 - val_loss: 0.7787 - val_acc: 0.6587\n",
      "\n",
      "Epoch 00019: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 20/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.3283 - acc: 0.8603 - val_loss: 0.9358 - val_acc: 0.6957\n",
      "\n",
      "Epoch 00020: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 21/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.2131 - acc: 0.9145 - val_loss: 1.1720 - val_acc: 0.5804\n",
      "\n",
      "Epoch 00021: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 22/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.1123 - acc: 0.9610 - val_loss: 2.4025 - val_acc: 0.6130\n",
      "\n",
      "Epoch 00022: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 23/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0570 - acc: 0.9835 - val_loss: 2.5279 - val_acc: 0.6565\n",
      "\n",
      "Epoch 00023: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 24/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0382 - acc: 0.9879 - val_loss: 2.6587 - val_acc: 0.6457\n",
      "\n",
      "Epoch 00024: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 25/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0215 - acc: 0.9937 - val_loss: 2.7957 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00025: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 26/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0204 - acc: 0.9949 - val_loss: 2.8051 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00026: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 27/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 2.8643 - val_acc: 0.6457\n",
      "\n",
      "Epoch 00027: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 28/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0104 - acc: 0.9973 - val_loss: 2.9899 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00028: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 29/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 3.5535 - val_acc: 0.6761\n",
      "\n",
      "Epoch 00029: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "Epoch 30/30\n",
      "4131/4131 [==============================] - 28s 7ms/step - loss: 0.0568 - acc: 0.9930 - val_loss: 3.2308 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00030: saving model to C:\\Users\\tanho\\Downloads\\Aaron-Workspace\\DAM-DHM-V-30.h5\n",
      "460/460 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 101, 1000, 32)     320       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 101, 1000, 32)     9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_31 (Averag (None, 25, 333, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 25, 333, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 25, 333, 64)       36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_32 (Averag (None, 6, 111, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 6, 111, 96)        55392     \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 6, 111, 96)        83040     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_33 (Averag (None, 1, 37, 96)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3552)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               909568    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,179,041\n",
      "Trainable params: 1,179,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Accuracy before K-Fold:  0.8179052691092977\n",
      "val_acc:  0.6152173918226491\n",
      "Model Accuracy after K-Fold:  0.7019565217909605\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation, k = 10\n",
    "\n",
    "n_folds = 10\n",
    "count = 0\n",
    "cv_scores, model_history = list(), list()\n",
    "for _ in range(n_folds):\n",
    "    # split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(newNPX, npY, test_size=0.10, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    # evaluate model\n",
    "    model, test_acc = evaluate_model(X_train, X_val, y_train, y_val)\n",
    "    count += 1\n",
    "    cv_scores.append(test_acc)\n",
    "    model_history.append(model)\n",
    "    print('K-Fold has ran ', count, ' times')\n",
    "    \n",
    "print('\\nModel Accuracy after all K-Fold: ', (np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67006874]\n",
      "[0.6867978]\n",
      "[0.6458308]\n",
      "[0.6805024]\n",
      "[0.7335013]\n",
      "[0.67324644]\n",
      "[0.74081373]\n",
      "[0.7228327]\n",
      "[0.67381525]\n",
      "[0.65047807]\n",
      "[0.6291201]\n",
      "[0.65658724]\n",
      "[0.6722251]\n",
      "[0.6627605]\n",
      "[0.69858]\n",
      "[0.6795434]\n",
      "[0.6168731]\n",
      "[0.68014544]\n",
      "[0.654198]\n",
      "[0.68004155]\n",
      "[0.681952]\n",
      "[0.65644014]\n",
      "[0.6521288]\n",
      "[0.654008]\n",
      "[0.6328309]\n",
      "[0.6890311]\n",
      "[0.6559533]\n",
      "[0.6681738]\n",
      "[0.67244244]\n",
      "[0.64830637]\n",
      "[0.7148792]\n",
      "[0.6750471]\n",
      "[0.68882346]\n",
      "[0.66350317]\n",
      "[0.6406661]\n",
      "[0.64942265]\n",
      "[0.67649937]\n",
      "[0.71295863]\n",
      "[0.7029922]\n",
      "[0.65047467]\n",
      "[0.64842266]\n",
      "[0.7030382]\n",
      "[0.6649402]\n",
      "[0.6594435]\n",
      "[0.6526973]\n",
      "[0.6450184]\n",
      "[0.6911686]\n",
      "[0.6500969]\n",
      "[0.6386665]\n",
      "[0.6863981]\n",
      "[0.6683552]\n",
      "[0.6907112]\n",
      "[0.6612068]\n",
      "[0.65292215]\n",
      "[0.6948359]\n",
      "[0.64810765]\n",
      "[0.66757846]\n",
      "[0.642527]\n",
      "[0.6308431]\n",
      "[0.6619879]\n",
      "[0.6717275]\n",
      "[0.66501456]\n",
      "[0.68367374]\n",
      "[0.660515]\n",
      "[0.6717639]\n",
      "[0.67846674]\n",
      "[0.7058482]\n",
      "[0.6940516]\n",
      "[0.66579384]\n",
      "[0.6841956]\n",
      "[0.6617938]\n",
      "[0.69447774]\n",
      "[0.6811924]\n",
      "[0.65719223]\n",
      "[0.6900504]\n",
      "[0.67798954]\n",
      "[0.6778217]\n",
      "[0.68577707]\n",
      "[0.68008953]\n",
      "[0.6703056]\n",
      "[0.6892375]\n",
      "[0.69929624]\n",
      "[0.6790572]\n",
      "[0.68580884]\n",
      "[0.670164]\n",
      "[0.675933]\n",
      "[0.6835256]\n",
      "[0.6755215]\n",
      "[0.6795176]\n",
      "[0.6612526]\n",
      "[0.68077224]\n",
      "[0.6901513]\n",
      "[0.67717314]\n",
      "[0.6759519]\n",
      "[0.6573797]\n",
      "[0.69050014]\n",
      "[0.6765435]\n",
      "[0.66746825]\n",
      "[0.6710626]\n",
      "[0.6615429]\n",
      "[0.67002785]\n",
      "[0.68942404]\n",
      "[0.68173015]\n",
      "[0.6720668]\n",
      "[0.67522824]\n",
      "[0.69614196]\n",
      "[0.67943394]\n",
      "[0.6732966]\n",
      "[0.6883004]\n",
      "[0.6663003]\n",
      "[0.6678272]\n",
      "[0.67812514]\n",
      "[0.67137957]\n",
      "[0.6845176]\n",
      "[0.66739553]\n",
      "[0.63997734]\n",
      "[0.6652585]\n",
      "[0.6774553]\n",
      "[0.66792977]\n",
      "[0.6710989]\n",
      "[0.6603262]\n",
      "[0.70035225]\n",
      "[0.6648098]\n",
      "[0.6651221]\n",
      "[0.67012703]\n",
      "[0.66590315]\n",
      "[0.67208093]\n",
      "[0.65781975]\n",
      "[0.66405845]\n",
      "[0.65919363]\n",
      "[0.67192596]\n",
      "[0.6709257]\n",
      "[0.6651167]\n",
      "[0.6705266]\n",
      "[0.6741282]\n",
      "[0.67719996]\n",
      "[0.6729441]\n",
      "[0.66035986]\n",
      "[0.67596865]\n",
      "[0.67332053]\n",
      "[0.6818633]\n",
      "[0.68332136]\n",
      "[0.6615769]\n",
      "[0.65020806]\n",
      "[0.6248358]\n",
      "[0.68078613]\n",
      "[0.6703596]\n",
      "[0.6529632]\n",
      "[0.6787154]\n",
      "[0.67662823]\n",
      "[0.7224798]\n",
      "[0.6420083]\n",
      "[0.6469021]\n",
      "[0.6976559]\n",
      "[0.67629075]\n",
      "[0.7073089]\n",
      "[0.5950189]\n",
      "[0.6780122]\n",
      "[0.6268943]\n",
      "[0.6255901]\n",
      "[0.6747547]\n",
      "[0.68470347]\n",
      "[0.5861536]\n",
      "[0.6129314]\n",
      "[0.62519276]\n",
      "[0.64493173]\n",
      "[0.5916379]\n",
      "[0.6038289]\n",
      "[0.6588346]\n",
      "[0.6426741]\n",
      "[0.6322309]\n",
      "[0.6573174]\n",
      "[0.5984199]\n",
      "[0.6420511]\n",
      "[0.60859406]\n",
      "[0.6283469]\n",
      "[0.5927275]\n",
      "[0.600045]\n",
      "[0.6699624]\n",
      "[0.5809336]\n",
      "[0.62919587]\n",
      "[0.6293684]\n",
      "[0.6242943]\n",
      "[0.60282177]\n",
      "[0.6564489]\n",
      "[0.5879273]\n",
      "[0.6124309]\n",
      "[0.6720467]\n",
      "[0.67916614]\n",
      "[0.6518363]\n",
      "[0.6046197]\n",
      "[0.6603134]\n",
      "[0.66169]\n",
      "[0.65250105]\n",
      "[0.668031]\n",
      "[0.5890023]\n",
      "[0.6305219]\n",
      "[0.6474896]\n",
      "[0.64503014]\n",
      "[0.6176059]\n",
      "[0.6452222]\n",
      "[0.5785911]\n",
      "[0.64006454]\n",
      "[0.6625848]\n",
      "[0.59155965]\n",
      "[0.5848179]\n",
      "[0.61590904]\n",
      "[0.65996313]\n",
      "[0.58499867]\n",
      "[0.57070786]\n",
      "[0.6862587]\n",
      "[0.63064325]\n",
      "[0.5521546]\n",
      "[0.5801457]\n",
      "[0.6278876]\n",
      "[0.63723904]\n",
      "[0.6420385]\n",
      "[0.63153666]\n",
      "[0.6334762]\n",
      "[0.6315016]\n",
      "[0.6406666]\n",
      "[0.6598288]\n",
      "[0.6648442]\n",
      "[0.617656]\n",
      "[0.6226278]\n",
      "[0.58818907]\n",
      "[0.65263325]\n",
      "[0.6050842]\n",
      "[0.6459686]\n",
      "[0.6509499]\n",
      "[0.67866665]\n",
      "[0.62032604]\n",
      "[0.6575693]\n",
      "[0.61762905]\n",
      "[0.66057503]\n",
      "[0.6352218]\n",
      "[0.6275587]\n",
      "[0.5824939]\n",
      "[0.6723603]\n",
      "[0.64705676]\n",
      "[0.6636257]\n",
      "[0.60236084]\n",
      "[0.6092481]\n",
      "[0.6238069]\n",
      "[0.5836692]\n",
      "[0.66557395]\n",
      "[0.6290996]\n",
      "[0.6348795]\n",
      "[0.66751724]\n",
      "[0.67829597]\n",
      "[0.6472269]\n",
      "[0.61250657]\n",
      "[0.58625424]\n",
      "[0.6177571]\n",
      "[0.64266336]\n",
      "[0.66008914]\n",
      "[0.65371853]\n",
      "[0.6321999]\n",
      "[0.6663744]\n",
      "[0.6491084]\n",
      "[0.64716303]\n",
      "[0.6010566]\n",
      "[0.6586298]\n",
      "[0.61635405]\n",
      "[0.6511042]\n",
      "[0.6256074]\n",
      "[0.61518073]\n",
      "[0.6753887]\n",
      "[0.6636418]\n",
      "[0.6347591]\n",
      "[0.56638825]\n",
      "[0.6188117]\n",
      "[0.6783476]\n",
      "[0.65740454]\n",
      "[0.648655]\n",
      "[0.6507994]\n",
      "[0.65646213]\n",
      "[0.5856051]\n",
      "[0.649578]\n",
      "[0.64593846]\n",
      "[0.64540064]\n",
      "[0.64362454]\n",
      "[0.66599995]\n",
      "[0.59194636]\n",
      "[0.59889024]\n",
      "[0.62233734]\n",
      "[0.61922777]\n",
      "[0.60531986]\n",
      "[0.5998322]\n",
      "[0.5908226]\n",
      "[0.64562654]\n",
      "[0.59785986]\n",
      "[0.6002095]\n",
      "[0.6202303]\n",
      "[0.5904342]\n",
      "[0.5668152]\n",
      "[0.5946764]\n",
      "[0.61614686]\n",
      "[0.59099185]\n",
      "[0.593858]\n",
      "[0.623242]\n",
      "[0.56183684]\n",
      "[0.63075864]\n",
      "[0.6184552]\n",
      "[0.63131404]\n",
      "[0.6106771]\n",
      "[0.6019692]\n",
      "[0.60853416]\n",
      "[0.617531]\n",
      "[0.61360204]\n",
      "[0.5851989]\n",
      "[0.5765127]\n",
      "[0.62758964]\n",
      "[0.63354427]\n",
      "[0.6348504]\n",
      "[0.6011751]\n",
      "[0.5641884]\n",
      "[0.6476304]\n",
      "[0.5946832]\n",
      "[0.61026895]\n",
      "[0.6221528]\n",
      "[0.6359829]\n",
      "[0.6790497]\n",
      "[0.6473533]\n",
      "[0.667681]\n",
      "[0.6180412]\n",
      "[0.60122705]\n",
      "[0.64229566]\n",
      "[0.6312293]\n",
      "[0.64975023]\n",
      "[0.647395]\n",
      "[0.65197533]\n",
      "[0.6560793]\n",
      "[0.61996377]\n",
      "[0.61706877]\n",
      "[0.6922403]\n",
      "[0.6417992]\n",
      "[0.6332922]\n",
      "[0.6009328]\n",
      "[0.60802466]\n",
      "[0.68132603]\n",
      "[0.6112776]\n",
      "[0.64216226]\n",
      "[0.652155]\n",
      "[0.6646312]\n",
      "[0.6118083]\n",
      "[0.6439268]\n",
      "[0.6099918]\n",
      "[0.63036656]\n",
      "[0.6635184]\n",
      "[0.6063172]\n",
      "[0.68801254]\n",
      "[0.63748896]\n",
      "[0.6356511]\n",
      "[0.6067567]\n",
      "[0.68096393]\n",
      "[0.6794042]\n",
      "[0.6667506]\n",
      "[0.61879945]\n",
      "[0.6513282]\n",
      "[0.6714063]\n",
      "[0.61022437]\n",
      "[0.6446023]\n",
      "[0.60887283]\n",
      "[0.6320628]\n",
      "[0.615832]\n",
      "[0.6068244]\n",
      "[0.6059115]\n",
      "[0.65933716]\n",
      "[0.65184724]\n",
      "[0.6746128]\n",
      "[0.67143375]\n",
      "[0.625188]\n",
      "[0.66245586]\n",
      "[0.66212696]\n",
      "[0.6933687]\n",
      "[0.62867045]\n",
      "[0.6337347]\n",
      "[0.61973083]\n",
      "[0.6442737]\n",
      "[0.64202154]\n",
      "[0.640136]\n",
      "[0.69331765]\n",
      "[0.6224596]\n",
      "[0.6290801]\n",
      "[0.6373577]\n",
      "[0.61147666]\n",
      "[0.62471354]\n",
      "[0.6306178]\n",
      "[0.63833386]\n",
      "[0.6591026]\n",
      "[0.627613]\n",
      "[0.6388885]\n",
      "[0.6796899]\n",
      "[0.6304317]\n",
      "[0.63379896]\n",
      "[0.67007685]\n",
      "[0.6529759]\n",
      "[0.67588365]\n",
      "[0.63240683]\n",
      "[0.6366452]\n",
      "[0.6294909]\n",
      "[0.66984314]\n",
      "[0.658931]\n",
      "[0.6348577]\n",
      "[0.6652066]\n",
      "[0.67195046]\n",
      "[0.6666928]\n",
      "[0.6480283]\n",
      "[0.59968054]\n",
      "[0.664708]\n",
      "[0.668158]\n",
      "[0.64586055]\n",
      "[0.6088207]\n",
      "[0.6254209]\n",
      "[0.63366306]\n",
      "[0.670395]\n",
      "[0.65516204]\n",
      "[0.6679655]\n",
      "[0.63556474]\n",
      "[0.6490576]\n",
      "[0.6525496]\n",
      "[0.67785215]\n",
      "[0.6295476]\n",
      "[0.65888834]\n",
      "[0.65435505]\n",
      "[0.6589687]\n",
      "[0.6111334]\n",
      "[0.6470489]\n",
      "[0.6324485]\n",
      "[0.6054587]\n",
      "[0.61633974]\n",
      "[0.6419054]\n",
      "[0.6434513]\n",
      "[0.6150441]\n",
      "[0.61173666]\n",
      "[0.6179607]\n",
      "[0.63539946]\n",
      "[0.6271279]\n",
      "[0.64375806]\n",
      "[0.64071405]\n",
      "[0.59975874]\n",
      "[0.64158714]\n",
      "[0.5945536]\n",
      "[0.65879506]\n",
      "[0.6299541]\n",
      "[0.65235996]\n",
      "[0.6433985]\n",
      "[0.62703454]\n",
      "[0.6370353]\n",
      "[0.5954805]\n",
      "[0.6637791]\n",
      "[0.61062616]\n",
      "[0.5979077]\n",
      "[0.63212764]\n",
      "[0.574963]\n",
      "[0.61137754]\n",
      "[0.63850456]\n",
      "[0.59234935]\n",
      "[0.5974224]\n",
      "[0.6535951]\n",
      "[0.58328855]\n",
      "[0.6605898]\n",
      "[0.5903898]\n",
      "[0.6224464]\n",
      "[0.63278264]\n",
      "[0.63832784]\n",
      "[0.63587815]\n",
      "[0.64198667]\n",
      "[0.63829434]\n",
      "[0.65136015]\n",
      "[0.6331928]\n",
      "[0.62780255]\n",
      "[0.6705372]\n",
      "[0.6504662]\n",
      "[0.6693804]\n",
      "[0.6496761]\n",
      "[0.60619444]\n",
      "[0.6697515]\n",
      "[0.6313663]\n",
      "[0.6467823]\n",
      "[0.656321]\n",
      "[0.5949132]\n",
      "[0.63638866]\n",
      "[0.6068827]\n",
      "[0.6359238]\n",
      "[0.60983676]\n",
      "[0.63293904]\n",
      "[0.5959413]\n",
      "[0.6121993]\n",
      "[0.6229655]\n",
      "[0.6343312]\n",
      "[0.6125701]\n",
      "[0.6298438]\n",
      "[0.6410147]\n",
      "[0.6433987]\n",
      "[0.6406862]\n",
      "[0.6683453]\n",
      "[0.6019526]\n",
      "[0.611002]\n",
      "[0.6296016]\n",
      "[0.6399538]\n",
      "[0.64447737]\n",
      "[0.609101]\n",
      "[0.6246506]\n",
      "[0.5932415]\n",
      "[0.67926466]\n",
      "[0.64867926]\n",
      "[0.6810036]\n",
      "[0.61780864]\n",
      "[0.66845083]\n",
      "[0.5969161]\n",
      "[0.6195974]\n",
      "[0.6245422]\n",
      "[0.635218]\n",
      "[0.65170085]\n",
      "[0.6281557]\n",
      "[0.6579839]\n",
      "[0.64079916]\n",
      "[0.6448751]\n",
      "[0.6168428]\n",
      "[0.6073699]\n",
      "[0.66408944]\n",
      "[0.63068306]\n",
      "[0.6377549]\n",
      "[0.6463546]\n",
      "[0.5970194]\n",
      "[0.6440315]\n",
      "[0.62085915]\n",
      "[0.6762836]\n",
      "[0.59402394]\n",
      "[0.63705254]\n",
      "[0.6352114]\n",
      "[0.65354216]\n",
      "[0.60975146]\n",
      "[0.6238464]\n",
      "[0.6282388]\n",
      "[0.6267301]\n",
      "[0.5985346]\n",
      "[0.6308456]\n",
      "[0.61029345]\n",
      "[0.6656904]\n",
      "[0.5996664]\n",
      "[0.612592]\n",
      "[0.64174414]\n",
      "[0.6101518]\n",
      "[0.6016308]\n",
      "[0.5819137]\n",
      "[0.5863248]\n",
      "[0.5983228]\n",
      "[0.5387388]\n",
      "[0.6367059]\n",
      "[0.6230733]\n",
      "[0.5994971]\n",
      "[0.6429473]\n",
      "[0.6426467]\n",
      "[0.64940846]\n",
      "[0.6656536]\n",
      "[0.5770081]\n",
      "[0.63820565]\n",
      "[0.6207548]\n",
      "[0.64700896]\n",
      "[0.6294715]\n",
      "[0.61558205]\n",
      "[0.5973723]\n",
      "[0.6298229]\n",
      "[0.6480956]\n",
      "[0.635843]\n",
      "[0.65227723]\n",
      "[0.59733903]\n",
      "[0.60873437]\n",
      "[0.62177765]\n",
      "[0.62724113]\n",
      "[0.6216823]\n",
      "[0.640867]\n",
      "[0.65917253]\n",
      "[0.61785704]\n",
      "[0.6144491]\n",
      "[0.5886504]\n",
      "[0.5970944]\n",
      "[0.5944729]\n",
      "[0.62829965]\n",
      "[0.63297576]\n",
      "[0.6141873]\n",
      "[0.607218]\n",
      "[0.60637045]\n",
      "[0.61600155]\n",
      "[0.6522371]\n",
      "[0.59440076]\n",
      "[0.62955093]\n",
      "[0.65146047]\n",
      "[0.6221688]\n",
      "[0.6650609]\n",
      "[0.60640544]\n",
      "[0.59772754]\n",
      "[0.6077775]\n",
      "[0.6250877]\n",
      "[0.6440811]\n",
      "[0.64055383]\n",
      "[0.6513526]\n",
      "[0.6346583]\n",
      "[0.61690533]\n",
      "[0.6354352]\n",
      "[0.65464675]\n",
      "[0.6233759]\n",
      "[0.6319816]\n",
      "[0.62284374]\n",
      "[0.61907834]\n",
      "[0.6599148]\n",
      "[0.6252488]\n",
      "[0.63958204]\n",
      "[0.61713433]\n",
      "[0.63006794]\n",
      "[0.5912189]\n",
      "[0.5848793]\n",
      "[0.58866036]\n",
      "[0.6110591]\n",
      "[0.5936426]\n",
      "[0.584203]\n",
      "[0.57566106]\n",
      "[0.6314834]\n",
      "[0.62413824]\n",
      "[0.6599337]\n",
      "[0.6459774]\n",
      "[0.65990376]\n",
      "[0.6088814]\n",
      "[0.6426782]\n",
      "[0.6449041]\n",
      "[0.6574988]\n",
      "[0.5964697]\n",
      "[0.60998243]\n",
      "[0.61930627]\n",
      "[0.6576189]\n",
      "[0.65724885]\n",
      "[0.65797484]\n",
      "[0.682697]\n",
      "[0.6582632]\n",
      "[0.63792515]\n",
      "[0.654195]\n",
      "[0.59397596]\n",
      "[0.60721576]\n",
      "[0.6257899]\n",
      "[0.5850904]\n",
      "[0.6149802]\n",
      "[0.60622823]\n",
      "[0.6383922]\n",
      "[0.61851096]\n",
      "[0.67097247]\n",
      "[0.6247724]\n",
      "[0.6614024]\n",
      "[0.64170396]\n",
      "[0.5982728]\n",
      "[0.64588374]\n",
      "[0.6506507]\n",
      "[0.593385]\n",
      "[0.6414279]\n",
      "[0.6437602]\n",
      "[0.6150615]\n",
      "[0.5893299]\n",
      "[0.6124908]\n",
      "[0.64878356]\n",
      "[0.6019302]\n",
      "[0.7077935]\n",
      "[0.5979155]\n",
      "[0.62791705]\n",
      "[0.53079355]\n",
      "[0.58478117]\n",
      "[0.5910979]\n",
      "[0.5775923]\n",
      "[0.6790861]\n",
      "[0.6068618]\n",
      "[0.6471677]\n",
      "[0.609793]\n",
      "[0.6347748]\n",
      "[0.5811894]\n",
      "[0.6447955]\n",
      "[0.6445408]\n",
      "[0.63735396]\n",
      "[0.6280609]\n",
      "[0.65269154]\n",
      "[0.60571146]\n",
      "[0.65331703]\n",
      "[0.6320941]\n",
      "[0.6298295]\n",
      "[0.6257826]\n",
      "[0.6552409]\n",
      "[0.5830277]\n",
      "[0.6534287]\n",
      "[0.61174417]\n",
      "[0.6703739]\n",
      "[0.6281936]\n",
      "[0.6408104]\n",
      "[0.67821276]\n",
      "[0.6320708]\n",
      "[0.6002558]\n",
      "[0.64259624]\n",
      "[0.6321214]\n",
      "[0.639379]\n",
      "[0.6168333]\n",
      "[0.6634277]\n",
      "[0.6191526]\n",
      "[0.6316787]\n",
      "[0.632857]\n",
      "[0.6183143]\n",
      "[0.5998075]\n",
      "[0.6535875]\n",
      "[0.6677468]\n",
      "[0.645657]\n",
      "[0.6385274]\n",
      "[0.6590738]\n",
      "[0.59044963]\n",
      "[0.6656796]\n",
      "[0.6065196]\n",
      "[0.65118814]\n",
      "[0.63069797]\n",
      "[0.63757974]\n",
      "[0.6195134]\n",
      "[0.6295322]\n",
      "[0.64532053]\n",
      "[0.6387971]\n",
      "[0.6035889]\n",
      "[0.63904744]\n",
      "[0.61647]\n",
      "[0.5893889]\n",
      "[0.5715549]\n",
      "[0.61661243]\n",
      "[0.6191615]\n",
      "[0.617417]\n",
      "[0.62363935]\n",
      "[0.5855706]\n",
      "[0.6115896]\n",
      "[0.6228024]\n",
      "[0.6236765]\n",
      "[0.57563215]\n",
      "[0.5773839]\n",
      "[0.63313067]\n",
      "[0.61898816]\n",
      "[0.5849292]\n",
      "[0.6000134]\n",
      "[0.5889127]\n",
      "[0.5916718]\n",
      "[0.5688191]\n",
      "[0.6107372]\n",
      "[0.5707197]\n",
      "[0.6077245]\n",
      "[0.6049347]\n",
      "[0.6075065]\n",
      "[0.5942206]\n",
      "[0.54952383]\n",
      "[0.6101634]\n",
      "[0.60641336]\n",
      "[0.5905092]\n",
      "[0.569446]\n",
      "[0.5829806]\n",
      "[0.6028791]\n",
      "[0.62211335]\n",
      "[0.6419297]\n",
      "[0.59590185]\n",
      "[0.5984811]\n",
      "[0.60283625]\n",
      "[0.60031784]\n",
      "[0.6029575]\n",
      "[0.6052317]\n",
      "[0.6159696]\n",
      "[0.5925969]\n",
      "[0.61788094]\n",
      "[0.5811849]\n",
      "[0.63180935]\n",
      "[0.59969723]\n",
      "[0.6118791]\n",
      "[0.57578355]\n",
      "[0.5950117]\n",
      "[0.51534796]\n",
      "[0.59137416]\n",
      "[0.6259676]\n",
      "[0.60805285]\n",
      "[0.6090886]\n",
      "[0.5814492]\n",
      "[0.58771926]\n",
      "[0.6185332]\n",
      "[0.5693297]\n",
      "[0.65241337]\n",
      "[0.6404108]\n",
      "[0.6275356]\n",
      "[0.6075491]\n",
      "[0.6224606]\n",
      "[0.64719343]\n",
      "[0.6424997]\n",
      "[0.6160614]\n",
      "[0.6304005]\n",
      "[0.60256886]\n",
      "[0.6134846]\n",
      "[0.62681454]\n",
      "[0.62445986]\n",
      "[0.6444634]\n",
      "[0.62658715]\n",
      "[0.6016235]\n",
      "[0.5974334]\n",
      "[0.6761865]\n",
      "[0.6289834]\n",
      "[0.65837914]\n",
      "[0.64794844]\n",
      "[0.62349516]\n",
      "[0.6245931]\n",
      "[0.63798654]\n",
      "[0.6506902]\n",
      "[0.64607555]\n",
      "[0.6644909]\n",
      "[0.6177204]\n",
      "[0.6201016]\n",
      "[0.6220775]\n",
      "[0.6348813]\n",
      "[0.63637775]\n",
      "[0.6179398]\n",
      "[0.63547015]\n",
      "[0.60511637]\n",
      "[0.62417394]\n",
      "[0.63788915]\n",
      "[0.6172526]\n",
      "[0.62424713]\n",
      "[0.5937033]\n",
      "[0.6505916]\n",
      "[0.63993895]\n",
      "[0.60630524]\n",
      "[0.60112464]\n",
      "[0.6036595]\n",
      "[0.64680254]\n",
      "[0.63107026]\n",
      "[0.6166932]\n",
      "[0.623416]\n",
      "[0.6262108]\n",
      "[0.6193113]\n",
      "[0.6350157]\n",
      "[0.6291975]\n",
      "[0.61243576]\n",
      "[0.6177709]\n",
      "[0.6240425]\n",
      "[0.66514254]\n",
      "[0.61384904]\n",
      "[0.6329055]\n",
      "[0.6258402]\n",
      "[0.618931]\n",
      "[0.641272]\n",
      "[0.6144236]\n",
      "[0.5990641]\n",
      "[0.64077616]\n",
      "[0.639913]\n",
      "[0.62315506]\n",
      "[0.6216208]\n",
      "[0.61505973]\n",
      "[0.6165001]\n",
      "[0.65529966]\n",
      "[0.62543136]\n",
      "[0.6395048]\n",
      "[0.63412225]\n",
      "[0.665301]\n",
      "[0.590491]\n",
      "[0.6163704]\n",
      "[0.61068285]\n",
      "[0.62339956]\n",
      "[0.5831255]\n",
      "[0.65544045]\n",
      "[0.6050884]\n",
      "[0.6673188]\n",
      "[0.643726]\n",
      "[0.6266589]\n",
      "[0.59292287]\n",
      "[0.6152967]\n",
      "[0.6234042]\n",
      "[0.6133548]\n",
      "[0.63892627]\n",
      "[0.6119478]\n",
      "[0.6347845]\n",
      "[0.5893244]\n",
      "[0.6281109]\n",
      "[0.62864834]\n",
      "[0.6175321]\n",
      "[0.6187689]\n",
      "[0.6504892]\n",
      "[0.54821414]\n",
      "[0.54531497]\n",
      "[0.66047525]\n",
      "[0.617628]\n",
      "[0.5967292]\n",
      "[0.6790707]\n",
      "[0.6464083]\n",
      "[0.5991149]\n",
      "[0.62547904]\n",
      "[0.61183107]\n",
      "[0.6375533]\n",
      "[0.617549]\n",
      "[0.60894865]\n",
      "[0.64501464]\n",
      "[0.6010463]\n",
      "[0.6129069]\n",
      "[0.61024976]\n",
      "[0.61111945]\n",
      "[0.62773037]\n",
      "[0.6067945]\n",
      "[0.6345979]\n",
      "[0.6314169]\n",
      "[0.6287457]\n",
      "[0.62577415]\n",
      "[0.61837184]\n",
      "[0.65774083]\n",
      "[0.6175883]\n",
      "[0.6314219]\n",
      "[0.7050228]\n",
      "[0.6016501]\n",
      "[0.617109]\n",
      "[0.6270883]\n",
      "[0.62638336]\n",
      "[0.6339109]\n",
      "[0.617752]\n",
      "[0.6383696]\n",
      "[0.623527]\n",
      "[0.6794509]\n",
      "[0.6660541]\n",
      "[0.6057319]\n",
      "[0.67027897]\n",
      "[0.6012094]\n",
      "[0.63564634]\n",
      "[0.63455397]\n",
      "[0.70574814]\n",
      "[0.6566719]\n",
      "[0.6219465]\n",
      "[0.61776966]\n",
      "[0.6869807]\n",
      "[0.6293277]\n",
      "[0.63356483]\n",
      "[0.61294365]\n",
      "[0.6456781]\n",
      "[0.59905934]\n",
      "[0.6504792]\n",
      "[0.6307141]\n",
      "[0.6623822]\n",
      "[0.5784042]\n",
      "[0.69662774]\n",
      "[0.6322631]\n",
      "[0.63727796]\n",
      "[0.67319316]\n",
      "[0.60719043]\n",
      "[0.6906648]\n",
      "[0.6198175]\n",
      "[0.5865504]\n",
      "[0.68856454]\n",
      "[0.6078232]\n",
      "[0.55165935]\n",
      "[0.67263335]\n",
      "[0.6428268]\n",
      "[0.5823691]\n",
      "[0.6339018]\n",
      "[0.6534343]\n",
      "[0.5833259]\n",
      "[0.64305323]\n",
      "[0.65068257]\n",
      "[0.6317191]\n",
      "[0.65426314]\n",
      "[0.6008964]\n",
      "[0.61439884]\n",
      "[0.6189021]\n",
      "[0.597159]\n",
      "[0.6470275]\n",
      "[0.629838]\n",
      "[0.66306055]\n",
      "[0.6200859]\n",
      "[0.564066]\n",
      "[0.61611754]\n",
      "[0.61435974]\n",
      "[0.6118703]\n",
      "[0.63427687]\n",
      "[0.6181812]\n",
      "[0.63396084]\n",
      "[0.628056]\n",
      "[0.6201205]\n",
      "[0.65775037]\n",
      "[0.63746774]\n",
      "[0.6285367]\n",
      "[0.6251093]\n",
      "[0.6483051]\n",
      "[0.638164]\n",
      "[0.62746966]\n",
      "[0.62369597]\n",
      "[0.6109725]\n",
      "[0.62787026]\n",
      "[0.6142436]\n",
      "[0.5945101]\n",
      "[0.65855986]\n",
      "[0.60189044]\n",
      "[0.6385358]\n",
      "[0.6364299]\n",
      "[0.6520273]\n",
      "[0.6198995]\n",
      "[0.6272046]\n",
      "[0.6534434]\n",
      "[0.65706855]\n",
      "[0.58573747]\n",
      "[0.6087552]\n",
      "[0.6219151]\n",
      "[0.63501143]\n",
      "[0.57973695]\n",
      "[0.5714111]\n",
      "[0.5997792]\n",
      "[0.6227305]\n",
      "[0.5957932]\n",
      "[0.6016152]\n",
      "[0.6027169]\n",
      "[0.6131645]\n",
      "[0.6290554]\n",
      "[0.6147541]\n",
      "[0.5914176]\n",
      "[0.6127264]\n",
      "[0.614761]\n",
      "[0.5939917]\n",
      "[0.61128503]\n",
      "[0.64548934]\n",
      "[0.61622614]\n",
      "[0.623542]\n",
      "[0.61759233]\n",
      "[0.6077078]\n",
      "[0.6069135]\n",
      "[0.61635673]\n",
      "[0.6176246]\n",
      "[0.6013644]\n",
      "[0.6031513]\n",
      "[0.6256207]\n",
      "[0.636641]\n",
      "[0.63187706]\n",
      "[0.6057416]\n",
      "[0.6327079]\n",
      "[0.59711856]\n",
      "[0.66408193]\n",
      "[0.61591023]\n",
      "[0.6085526]\n",
      "[0.6021018]\n",
      "[0.64076626]\n",
      "[0.60623217]\n",
      "[0.6338531]\n",
      "[0.62215996]\n",
      "[0.6390194]\n",
      "[0.6088488]\n",
      "[0.59768575]\n",
      "[0.61564076]\n",
      "[0.60522854]\n",
      "[0.63006663]\n",
      "[0.5784429]\n",
      "[0.61193424]\n",
      "[0.66473186]\n",
      "[0.58738416]\n",
      "[0.64122677]\n",
      "[0.59898823]\n",
      "[0.62155515]\n",
      "[0.6300756]\n",
      "[0.6283212]\n",
      "[0.5815123]\n",
      "[0.63428956]\n",
      "[0.6354417]\n",
      "[0.6661606]\n",
      "[0.6497694]\n",
      "[0.5903525]\n",
      "[0.6665027]\n",
      "[0.62409633]\n",
      "[0.62263274]\n",
      "[0.6540451]\n",
      "[0.61686796]\n",
      "[0.63304454]\n",
      "[0.6494995]\n",
      "[0.62082464]\n",
      "[0.6700462]\n",
      "[0.66090846]\n",
      "[0.6192993]\n",
      "[0.60515374]\n",
      "[0.6482723]\n",
      "[0.6561029]\n",
      "[0.6315227]\n",
      "[0.6189111]\n",
      "[0.6180648]\n",
      "[0.6760576]\n",
      "[0.6386497]\n",
      "[0.6442391]\n",
      "[0.6566345]\n",
      "[0.6559013]\n",
      "[0.6482228]\n",
      "[0.5704123]\n",
      "[0.6345262]\n",
      "[0.6540512]\n",
      "[0.5716083]\n",
      "[0.6320468]\n",
      "[0.6129371]\n",
      "[0.6532472]\n",
      "[0.6049869]\n",
      "[0.6068886]\n",
      "[0.65521204]\n",
      "[0.5985473]\n",
      "[0.6499548]\n",
      "[0.65395105]\n",
      "[0.647908]\n",
      "[0.6373699]\n",
      "[0.6446154]\n",
      "[0.6660257]\n",
      "[0.6210041]\n",
      "[0.6511525]\n",
      "[0.5899318]\n",
      "[0.64874995]\n",
      "[0.6554118]\n",
      "[0.6474072]\n",
      "[0.64274263]\n",
      "[0.6377716]\n",
      "[0.60636646]\n",
      "[0.6262399]\n",
      "[0.63743263]\n",
      "[0.6497155]\n",
      "[0.6522412]\n",
      "[0.628754]\n",
      "[0.64816636]\n",
      "[0.6671869]\n",
      "[0.6688704]\n",
      "[0.65344495]\n",
      "[0.6948852]\n",
      "[0.6776864]\n",
      "[0.67489254]\n",
      "[0.6324066]\n",
      "[0.59877664]\n",
      "[0.64453274]\n",
      "[0.6121194]\n",
      "[0.637054]\n",
      "[0.67443407]\n",
      "[0.6471523]\n",
      "[0.65948683]\n",
      "[0.6322962]\n",
      "[0.6412538]\n",
      "[0.63516283]\n",
      "[0.6473939]\n",
      "[0.66679347]\n",
      "[0.67343986]\n",
      "[0.6671002]\n",
      "[0.6022792]\n",
      "[0.60933286]\n",
      "[0.63947105]\n",
      "[0.5949362]\n",
      "[0.67063713]\n",
      "[0.5941781]\n",
      "[0.6437888]\n",
      "[0.6669844]\n",
      "[0.66559476]\n",
      "[0.6579602]\n",
      "[0.70958495]\n",
      "[0.6558231]\n",
      "[0.6654457]\n",
      "[0.6582072]\n",
      "[0.6707152]\n",
      "[0.6242388]\n",
      "[0.679155]\n",
      "[0.6320501]\n",
      "[0.704439]\n",
      "[0.650719]\n",
      "[0.6550869]\n",
      "[0.5888695]\n",
      "[0.6797602]\n",
      "[0.65535426]\n",
      "[0.6501514]\n",
      "[0.6212466]\n",
      "[0.6767485]\n",
      "[0.6416824]\n",
      "[0.6902455]\n",
      "[0.68109155]\n",
      "[0.63031274]\n",
      "[0.59338063]\n",
      "[0.59525573]\n",
      "[0.61812174]\n",
      "[0.653175]\n",
      "[0.666086]\n",
      "[0.647326]\n",
      "[0.65581214]\n",
      "[0.66354007]\n",
      "[0.56221557]\n",
      "[0.6299344]\n",
      "[0.6602735]\n",
      "[0.638792]\n",
      "[0.6196706]\n",
      "[0.66531897]\n",
      "[0.6438439]\n",
      "[0.6562536]\n",
      "[0.61564875]\n",
      "[0.5644497]\n",
      "[0.6357235]\n",
      "[0.6811323]\n",
      "[0.6270281]\n",
      "[0.653496]\n",
      "[0.6384439]\n",
      "[0.605956]\n",
      "[0.6354103]\n",
      "[0.69584346]\n",
      "[0.62434167]\n",
      "[0.6540072]\n",
      "[0.699157]\n",
      "[0.5845063]\n",
      "[0.61778706]\n",
      "[0.6401459]\n",
      "[0.60502696]\n",
      "[0.6016613]\n",
      "[0.6016677]\n",
      "[0.6199468]\n",
      "[0.5974464]\n",
      "[0.6453175]\n",
      "[0.59637684]\n",
      "[0.6148365]\n",
      "[0.5993788]\n",
      "[0.6137358]\n",
      "[0.6006779]\n",
      "[0.59885097]\n",
      "[0.58617365]\n",
      "[0.61517507]\n",
      "[0.60349524]\n",
      "[0.61116195]\n",
      "[0.5971279]\n",
      "[0.59905094]\n",
      "[0.62975353]\n",
      "[0.6116644]\n",
      "[0.6227213]\n",
      "[0.61154914]\n",
      "[0.6113706]\n",
      "[0.61583185]\n",
      "[0.57931554]\n",
      "[0.620472]\n",
      "[0.62233293]\n",
      "[0.6015285]\n",
      "[0.58786684]\n",
      "[0.5926098]\n",
      "[0.6133541]\n",
      "[0.6117836]\n",
      "[0.62012374]\n",
      "[0.5976964]\n",
      "[0.59676147]\n",
      "[0.5868529]\n",
      "[0.6374622]\n",
      "[0.59857213]\n",
      "[0.6286614]\n",
      "[0.62653756]\n",
      "[0.6367161]\n",
      "[0.59573287]\n",
      "[0.616987]\n",
      "[0.6430029]\n",
      "[0.6182701]\n",
      "[0.5972901]\n",
      "[0.6232616]\n",
      "[0.5789465]\n",
      "[0.64777964]\n",
      "[0.6396769]\n",
      "[0.6183225]\n",
      "[0.63722116]\n",
      "[0.62588286]\n",
      "[0.6322522]\n",
      "[0.6270011]\n",
      "[0.6408727]\n",
      "[0.6211528]\n",
      "[0.62095654]\n",
      "[0.6116012]\n",
      "[0.57302797]\n",
      "[0.64467204]\n",
      "[0.61880517]\n",
      "[0.6341665]\n",
      "[0.5981542]\n",
      "[0.61427623]\n",
      "[0.6496827]\n",
      "[0.6297173]\n",
      "[0.6034046]\n",
      "[0.59819347]\n",
      "[0.63216704]\n",
      "[0.61892104]\n",
      "[0.62159795]\n",
      "[0.6316209]\n",
      "[0.5814897]\n",
      "[0.62958467]\n",
      "[0.59646744]\n",
      "[0.59832186]\n",
      "[0.64686865]\n",
      "[0.6160182]\n",
      "[0.64355093]\n",
      "[0.6281527]\n",
      "[0.6083906]\n",
      "[0.60132045]\n",
      "[0.6332432]\n",
      "[0.5989422]\n",
      "[0.6323968]\n",
      "[0.61632997]\n",
      "[0.67272455]\n",
      "[0.6606201]\n",
      "[0.653738]\n",
      "[0.6481698]\n",
      "[0.6313289]\n",
      "[0.64749974]\n",
      "[0.6301958]\n",
      "[0.64496267]\n",
      "[0.6801865]\n",
      "[0.6868271]\n",
      "[0.6531383]\n",
      "[0.61080915]\n",
      "[0.6748145]\n",
      "[0.6186703]\n",
      "[0.6196843]\n",
      "[0.64159644]\n",
      "[0.6205139]\n",
      "[0.5867494]\n",
      "[0.6038893]\n",
      "[0.63083994]\n",
      "[0.6354184]\n",
      "[0.6179308]\n",
      "[0.6662024]\n",
      "[0.6301852]\n",
      "[0.65406746]\n",
      "[0.6207201]\n",
      "[0.59251195]\n",
      "[0.64865476]\n",
      "[0.6502585]\n",
      "[0.6195527]\n",
      "[0.64745396]\n",
      "[0.64380974]\n",
      "[0.61015856]\n",
      "[0.6371702]\n",
      "[0.6133848]\n",
      "[0.6431599]\n",
      "[0.6554506]\n",
      "[0.63347864]\n",
      "[0.62560993]\n",
      "[0.62075865]\n",
      "[0.65576166]\n",
      "[0.67003036]\n",
      "[0.6961025]\n",
      "[0.62269723]\n",
      "[0.652672]\n",
      "[0.6440786]\n",
      "[0.665923]\n",
      "[0.635301]\n",
      "[0.5960715]\n",
      "[0.6360256]\n",
      "[0.65719223]\n",
      "[0.6330243]\n",
      "[0.6114001]\n",
      "[0.6641481]\n",
      "[0.6393812]\n",
      "[0.62992054]\n",
      "[0.656631]\n",
      "[0.64699996]\n",
      "[0.6465602]\n",
      "[0.63237816]\n",
      "[0.5973521]\n",
      "[0.6189071]\n",
      "[0.6209409]\n",
      "[0.64177215]\n",
      "[0.6212165]\n",
      "[0.68332565]\n",
      "[0.6019602]\n",
      "[0.6478896]\n",
      "[0.64397836]\n",
      "[0.6227413]\n",
      "[0.6406446]\n",
      "[0.6266598]\n",
      "[0.5956642]\n",
      "[0.6115004]\n",
      "[0.649033]\n",
      "[0.64923656]\n",
      "[0.58933425]\n",
      "[0.6166346]\n",
      "[0.643671]\n",
      "[0.6595401]\n",
      "[0.64749956]\n",
      "[0.62274885]\n",
      "[0.6219305]\n",
      "[0.6252109]\n",
      "[0.63188565]\n",
      "[0.5679159]\n",
      "[0.6173647]\n",
      "[0.59263533]\n",
      "[0.6682231]\n",
      "[0.6193767]\n",
      "[0.6031182]\n",
      "[0.6083357]\n",
      "[0.6942949]\n",
      "[0.62538975]\n",
      "[0.62847686]\n",
      "[0.6292895]\n",
      "[0.6477311]\n",
      "[0.60431486]\n",
      "[0.6436001]\n",
      "[0.63872594]\n",
      "[0.62056977]\n",
      "[0.6307678]\n",
      "[0.6460066]\n",
      "[0.6281383]\n",
      "[0.6451848]\n",
      "[0.62827104]\n",
      "[0.67977196]\n",
      "[0.6342496]\n",
      "[0.6525347]\n",
      "[0.6180819]\n",
      "[0.60823005]\n",
      "[0.61044496]\n",
      "[0.6136911]\n",
      "[0.6346687]\n",
      "[0.6187327]\n",
      "[0.6602781]\n",
      "[0.5795076]\n",
      "[0.5914898]\n",
      "[0.6066032]\n",
      "[0.5999906]\n",
      "[0.6210882]\n",
      "[0.6547003]\n",
      "[0.6389907]\n",
      "[0.61263305]\n",
      "[0.64328986]\n",
      "[0.64848715]\n",
      "[0.6589862]\n",
      "[0.6605919]\n",
      "[0.66277456]\n",
      "[0.680816]\n",
      "[0.6532375]\n",
      "[0.6531231]\n",
      "[0.63206685]\n",
      "[0.68512416]\n",
      "[0.62839293]\n",
      "[0.62871796]\n",
      "[0.60981315]\n",
      "[0.60704947]\n",
      "[0.6536406]\n",
      "[0.6441884]\n",
      "[0.6144006]\n",
      "[0.64743936]\n",
      "[0.65920585]\n",
      "[0.61974794]\n",
      "[0.598343]\n",
      "[0.6757977]\n",
      "[0.582706]\n",
      "[0.67873144]\n",
      "[0.6273395]\n",
      "[0.6196172]\n",
      "[0.6126437]\n",
      "[0.5612221]\n",
      "[0.65371877]\n",
      "[0.64678776]\n",
      "[0.62946606]\n",
      "[0.66121733]\n",
      "[0.64497757]\n",
      "[0.6112368]\n",
      "[0.6416995]\n",
      "[0.706125]\n",
      "[0.58630794]\n",
      "[0.6753683]\n",
      "[0.63787585]\n",
      "[0.65874296]\n",
      "[0.6338922]\n",
      "[0.6597843]\n",
      "[0.6361259]\n",
      "[0.58716846]\n",
      "[0.5594785]\n",
      "[0.65773684]\n",
      "[0.6194881]\n",
      "[0.63446677]\n",
      "[0.5913082]\n",
      "[0.61071354]\n",
      "[0.64439845]\n",
      "[0.65969235]\n",
      "[0.6715994]\n",
      "[0.6632973]\n",
      "[0.6233398]\n",
      "[0.67494863]\n",
      "[0.6432963]\n",
      "[0.6403237]\n",
      "[0.66564727]\n",
      "[0.6105215]\n",
      "[0.6628648]\n",
      "[0.65914154]\n",
      "[0.6857222]\n",
      "[0.658992]\n",
      "[0.6300081]\n",
      "[0.66054344]\n",
      "[0.6143724]\n",
      "[0.6192488]\n",
      "[0.67312896]\n",
      "[0.6401324]\n",
      "[0.6242962]\n",
      "[0.6021737]\n",
      "[0.633951]\n",
      "[0.572983]\n",
      "[0.5955651]\n",
      "[0.60833275]\n",
      "[0.5742817]\n",
      "[0.5749512]\n",
      "[0.5807586]\n",
      "[0.5785329]\n",
      "[0.5970111]\n",
      "[0.5859933]\n",
      "[0.6112095]\n",
      "[0.59720945]\n",
      "[0.6222053]\n",
      "[0.6184271]\n",
      "[0.6128611]\n",
      "[0.64065665]\n",
      "[0.6225115]\n",
      "[0.6174793]\n",
      "[0.5794626]\n",
      "[0.6007834]\n",
      "[0.59013766]\n",
      "[0.62106353]\n",
      "[0.61277986]\n",
      "[0.6031473]\n",
      "[0.639915]\n",
      "[0.59910023]\n",
      "[0.5810108]\n",
      "[0.60902]\n",
      "[0.62101865]\n",
      "[0.60431683]\n",
      "[0.61536735]\n",
      "[0.597511]\n",
      "[0.5837362]\n",
      "[0.6061713]\n",
      "[0.59163195]\n",
      "[0.6053072]\n",
      "[0.60040355]\n",
      "[0.60044944]\n",
      "[0.5824942]\n",
      "[0.63530856]\n",
      "[0.63271457]\n",
      "[0.6236577]\n",
      "[0.5769285]\n",
      "[0.63634586]\n",
      "[0.5698469]\n",
      "[0.59563357]\n",
      "[0.59340626]\n",
      "[0.564373]\n",
      "[0.5894032]\n",
      "[0.61547095]\n",
      "[0.6287185]\n",
      "[0.5893416]\n",
      "[0.5724358]\n",
      "[0.6022604]\n",
      "[0.59081197]\n",
      "[0.61881965]\n",
      "[0.599942]\n",
      "[0.6460798]\n",
      "[0.59373486]\n",
      "[0.57800215]\n",
      "[0.59134394]\n",
      "[0.6166607]\n",
      "[0.5891099]\n",
      "[0.5881957]\n",
      "[0.6049567]\n",
      "[0.59409493]\n",
      "[0.5899938]\n",
      "[0.63165563]\n",
      "[0.6120227]\n",
      "[0.595215]\n",
      "[0.60892457]\n",
      "[0.57092714]\n",
      "[0.5776787]\n",
      "[0.6121056]\n",
      "[0.59993696]\n",
      "[0.63502896]\n",
      "[0.62453437]\n",
      "[0.60154384]\n",
      "[0.58607733]\n",
      "[0.5936299]\n",
      "[0.60870117]\n",
      "[0.6374212]\n",
      "[0.5880687]\n",
      "[0.61464447]\n",
      "[0.6286689]\n",
      "[0.6110213]\n",
      "[0.61339796]\n",
      "[0.611914]\n",
      "[0.63800764]\n",
      "[0.628735]\n",
      "[0.5919459]\n",
      "[0.6013577]\n",
      "[0.6339115]\n",
      "[0.6053429]\n",
      "[0.63739413]\n",
      "[0.6350932]\n",
      "[0.61095846]\n",
      "[0.6219444]\n",
      "[0.61783636]\n",
      "[0.6740869]\n",
      "[0.6243023]\n",
      "[0.5961661]\n",
      "[0.6024246]\n",
      "[0.6160796]\n",
      "[0.57898515]\n",
      "[0.58968556]\n",
      "[0.61063844]\n",
      "[0.6067868]\n",
      "[0.6327131]\n",
      "[0.6062394]\n",
      "[0.5672058]\n",
      "[0.62444806]\n",
      "[0.6241733]\n",
      "[0.6070195]\n",
      "[0.5969501]\n",
      "[0.54511887]\n",
      "[0.62422925]\n",
      "[0.5934737]\n",
      "[0.6191619]\n",
      "[0.5948081]\n",
      "[0.6188294]\n",
      "[0.6134993]\n",
      "[0.5782537]\n",
      "[0.64691216]\n",
      "[0.6204109]\n",
      "[0.6264268]\n",
      "[0.62684536]\n",
      "[0.6389224]\n",
      "[0.65473866]\n",
      "[0.62089205]\n",
      "[0.634892]\n",
      "[0.61346865]\n",
      "[0.6083272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6208962]\n",
      "[0.6170454]\n",
      "[0.60704255]\n",
      "[0.597344]\n",
      "[0.61931145]\n",
      "[0.59160304]\n",
      "[0.6623666]\n",
      "[0.63145864]\n",
      "[0.60982025]\n",
      "[0.65798026]\n",
      "[0.6264495]\n",
      "[0.62035525]\n",
      "[0.59073335]\n",
      "[0.5814898]\n",
      "[0.5991826]\n",
      "[0.6522672]\n",
      "[0.6068334]\n",
      "[0.6269746]\n",
      "[0.6262111]\n",
      "[0.61254287]\n",
      "[0.5764158]\n",
      "[0.63641554]\n",
      "[0.613021]\n",
      "[0.60051894]\n",
      "[0.615793]\n",
      "[0.6085661]\n",
      "[0.5839881]\n",
      "[0.6441444]\n",
      "[0.6346591]\n",
      "[0.64251554]\n",
      "[0.63197684]\n",
      "[0.6229242]\n",
      "[0.6468233]\n",
      "[0.63154864]\n",
      "[0.6438778]\n",
      "[0.6289761]\n",
      "[0.6234197]\n",
      "[0.6001253]\n",
      "[0.63057894]\n",
      "[0.63669306]\n",
      "[0.6624966]\n",
      "[0.6381746]\n",
      "[0.64141953]\n",
      "[0.6225457]\n",
      "[0.6097769]\n",
      "[0.60223126]\n",
      "[0.63513285]\n",
      "[0.59679556]\n",
      "[0.6025806]\n",
      "[0.63161767]\n",
      "[0.5983059]\n",
      "[0.59819555]\n",
      "[0.6148097]\n",
      "[0.63068616]\n",
      "[0.6397841]\n",
      "[0.5934433]\n",
      "[0.6608938]\n",
      "[0.6252583]\n",
      "[0.6230444]\n",
      "[0.60544497]\n",
      "[0.61641425]\n",
      "[0.57900536]\n",
      "[0.6077384]\n",
      "[0.62012506]\n",
      "[0.63010675]\n",
      "[0.6062742]\n",
      "[0.5848024]\n",
      "[0.6398063]\n",
      "[0.6065512]\n",
      "[0.6067162]\n",
      "[0.6222962]\n",
      "[0.5979254]\n",
      "[0.5586511]\n",
      "[0.6163823]\n",
      "[0.5795903]\n",
      "[0.6156366]\n",
      "[0.61432195]\n",
      "[0.62549555]\n",
      "[0.6309551]\n",
      "[0.5969281]\n",
      "[0.6281186]\n",
      "[0.6095477]\n",
      "[0.59928834]\n",
      "[0.6554738]\n",
      "[0.58398604]\n",
      "[0.6247326]\n",
      "[0.6250564]\n",
      "[0.6127415]\n",
      "[0.5942744]\n",
      "[0.62091374]\n",
      "[0.6707784]\n",
      "[0.6310155]\n",
      "[0.6278643]\n",
      "[0.62090075]\n",
      "[0.6440681]\n",
      "[0.6243161]\n",
      "[0.64139676]\n",
      "[0.60981107]\n",
      "[0.64277786]\n",
      "[0.6425743]\n",
      "[0.63046557]\n",
      "[0.59945685]\n",
      "[0.62355274]\n",
      "[0.64455295]\n",
      "[0.6319511]\n",
      "[0.6459704]\n",
      "[0.6101721]\n",
      "[0.6218593]\n",
      "[0.60566473]\n",
      "[0.59901327]\n",
      "[0.66217434]\n",
      "[0.5801554]\n",
      "[0.66296047]\n",
      "[0.6309191]\n",
      "[0.64303976]\n",
      "[0.60031617]\n",
      "[0.620677]\n",
      "[0.6201311]\n",
      "[0.5818379]\n",
      "[0.5861527]\n",
      "[0.6180589]\n",
      "[0.6406118]\n",
      "[0.63424504]\n",
      "[0.6316156]\n",
      "[0.6236956]\n",
      "[0.6242986]\n",
      "[0.636014]\n",
      "[0.6227798]\n",
      "[0.58953446]\n",
      "[0.604602]\n",
      "[0.633254]\n",
      "[0.6164602]\n",
      "[0.5793284]\n",
      "[0.6242152]\n",
      "[0.62287843]\n",
      "[0.6721147]\n",
      "[0.6285156]\n",
      "[0.6275467]\n",
      "[0.5983752]\n",
      "[0.6160231]\n",
      "[0.66440356]\n",
      "[0.62442756]\n",
      "[0.64960104]\n",
      "[0.6533591]\n",
      "[0.65291625]\n",
      "[0.6285601]\n",
      "[0.62888044]\n",
      "[0.5909407]\n",
      "[0.66008717]\n",
      "[0.6244391]\n",
      "[0.6645844]\n",
      "[0.6457954]\n",
      "[0.62268794]\n",
      "[0.6651593]\n",
      "[0.59937733]\n",
      "[0.64277625]\n",
      "[0.6455435]\n",
      "[0.64665633]\n",
      "[0.6598539]\n",
      "[0.6187017]\n",
      "[0.6450989]\n",
      "[0.625583]\n",
      "[0.60252154]\n",
      "[0.682776]\n",
      "[0.6557026]\n",
      "[0.6735454]\n",
      "[0.60481524]\n",
      "[0.62152815]\n",
      "[0.6181442]\n",
      "[0.59756976]\n",
      "[0.6537913]\n",
      "[0.6707613]\n",
      "[0.6259107]\n",
      "[0.64116687]\n",
      "[0.6456927]\n",
      "[0.6319148]\n",
      "[0.64275]\n",
      "[0.6770437]\n",
      "[0.6621301]\n",
      "[0.65243804]\n",
      "[0.6572822]\n",
      "[0.5906324]\n",
      "[0.65548253]\n",
      "[0.6745697]\n",
      "[0.616268]\n",
      "[0.6117799]\n",
      "[0.61203325]\n",
      "[0.5920421]\n",
      "[0.6121659]\n",
      "[0.6533778]\n",
      "[0.61046124]\n",
      "[0.65233314]\n",
      "[0.67250943]\n",
      "[0.6725809]\n",
      "[0.59184074]\n",
      "[0.65100026]\n",
      "[0.5986639]\n",
      "[0.6241281]\n",
      "[0.6165619]\n",
      "[0.6554568]\n",
      "[0.6395785]\n",
      "[0.65110093]\n",
      "[0.6532264]\n",
      "[0.6432302]\n",
      "[0.62907046]\n",
      "[0.6044665]\n",
      "[0.642099]\n",
      "[0.6119836]\n",
      "[0.6093534]\n",
      "[0.6202402]\n",
      "[0.6507776]\n",
      "[0.61672926]\n",
      "[0.607703]\n",
      "[0.6121774]\n",
      "[0.6351828]\n",
      "[0.64739597]\n",
      "[0.623387]\n",
      "[0.5990322]\n",
      "[0.57805675]\n",
      "[0.6089495]\n",
      "[0.61117846]\n",
      "[0.6011816]\n",
      "[0.64106834]\n",
      "[0.64223385]\n",
      "[0.6368372]\n",
      "[0.6096012]\n",
      "[0.62665284]\n",
      "[0.60075444]\n",
      "[0.60762835]\n",
      "[0.6135635]\n",
      "[0.6045388]\n",
      "[0.65361285]\n",
      "[0.6489037]\n",
      "[0.67533505]\n",
      "[0.5688429]\n",
      "[0.61678493]\n",
      "[0.57971764]\n",
      "[0.60734046]\n",
      "[0.5852933]\n",
      "[0.6157612]\n",
      "[0.61270934]\n",
      "[0.6040144]\n",
      "[0.58999926]\n",
      "[0.60210145]\n",
      "[0.5836963]\n",
      "[0.6025979]\n",
      "[0.58128273]\n",
      "[0.5965402]\n",
      "[0.61097276]\n",
      "[0.63064814]\n",
      "[0.61053824]\n",
      "[0.6067742]\n",
      "[0.5932646]\n",
      "[0.6199267]\n",
      "[0.60053897]\n",
      "[0.59592]\n",
      "[0.59409213]\n",
      "[0.5979205]\n",
      "[0.63523984]\n",
      "[0.5970973]\n",
      "[0.6258194]\n",
      "[0.5969617]\n",
      "[0.6112881]\n",
      "[0.6278755]\n",
      "[0.57705843]\n",
      "[0.61180556]\n",
      "[0.59513205]\n",
      "[0.6159734]\n",
      "[0.618995]\n",
      "[0.59303]\n",
      "[0.6072265]\n",
      "[0.6025771]\n",
      "[0.59183407]\n",
      "[0.62470835]\n",
      "[0.62269866]\n",
      "[0.6260017]\n",
      "[0.60855174]\n",
      "[0.5987402]\n",
      "[0.6096525]\n",
      "[0.5771996]\n",
      "[0.5833906]\n",
      "[0.64551365]\n",
      "[0.6206405]\n",
      "[0.5885438]\n",
      "[0.61080015]\n",
      "[0.6053227]\n",
      "[0.64164555]\n",
      "[0.60923576]\n",
      "[0.617601]\n",
      "[0.6528546]\n",
      "[0.6420809]\n",
      "[0.6300865]\n",
      "[0.6088991]\n",
      "[0.62806875]\n",
      "[0.62557966]\n",
      "[0.609138]\n",
      "[0.5948222]\n",
      "[0.5894315]\n",
      "[0.6455959]\n",
      "[0.621023]\n",
      "[0.6032031]\n",
      "[0.6109141]\n",
      "[0.6062288]\n",
      "[0.61955523]\n",
      "[0.6068772]\n",
      "[0.6182263]\n",
      "[0.6092892]\n",
      "[0.6147634]\n",
      "[0.6013975]\n",
      "[0.649439]\n",
      "[0.6538498]\n",
      "[0.6224037]\n",
      "[0.64223707]\n",
      "[0.63263655]\n",
      "[0.65720916]\n",
      "[0.6446216]\n",
      "[0.62147325]\n",
      "[0.6338158]\n",
      "[0.638137]\n",
      "[0.65577614]\n",
      "[0.6178934]\n",
      "[0.63695467]\n",
      "[0.64430135]\n",
      "[0.6575009]\n",
      "[0.58566076]\n",
      "[0.64046806]\n",
      "[0.6449555]\n",
      "[0.6615933]\n",
      "[0.6687545]\n",
      "[0.6370729]\n",
      "[0.65798235]\n",
      "[0.64197636]\n",
      "[0.64029694]\n",
      "[0.63728374]\n",
      "[0.6643828]\n",
      "[0.6222094]\n",
      "[0.6351829]\n",
      "[0.62087315]\n",
      "[0.6110483]\n",
      "[0.6189695]\n",
      "[0.67337894]\n",
      "[0.6289232]\n",
      "[0.5919299]\n",
      "[0.6021678]\n",
      "[0.66014576]\n",
      "[0.6266653]\n",
      "[0.6369153]\n",
      "[0.65615964]\n",
      "[0.63182557]\n",
      "[0.59130615]\n",
      "[0.64840204]\n",
      "[0.64134836]\n",
      "[0.6321052]\n",
      "[0.64015317]\n",
      "[0.5766382]\n",
      "[0.6102274]\n",
      "[0.5945845]\n",
      "[0.602214]\n",
      "[0.6345298]\n",
      "[0.628355]\n",
      "[0.62242836]\n",
      "[0.6350554]\n",
      "[0.6299544]\n",
      "[0.6064812]\n",
      "[0.65191436]\n",
      "[0.6584485]\n",
      "[0.59429884]\n",
      "[0.65961045]\n",
      "[0.62034404]\n",
      "[0.61176217]\n",
      "[0.613232]\n",
      "[0.6306007]\n",
      "[0.67832994]\n",
      "[0.6584244]\n",
      "[0.65775186]\n",
      "[0.6472024]\n",
      "[0.6645122]\n",
      "[0.62549365]\n",
      "[0.643818]\n",
      "[0.6967138]\n",
      "[0.64990944]\n",
      "[0.7051946]\n",
      "[0.67496306]\n",
      "[0.68222314]\n",
      "[0.65503573]\n",
      "[0.6757678]\n",
      "[0.61551166]\n",
      "[0.66548365]\n",
      "[0.6855905]\n",
      "[0.6385552]\n",
      "[0.66464496]\n",
      "[0.62120706]\n",
      "[0.669557]\n",
      "[0.69502014]\n",
      "[0.6784065]\n",
      "[0.65558875]\n",
      "[0.6766497]\n",
      "[0.64250636]\n",
      "[0.672488]\n",
      "[0.6886481]\n",
      "[0.65989965]\n",
      "[0.62172455]\n",
      "[0.6752498]\n",
      "[0.6439202]\n",
      "[0.66758597]\n",
      "[0.67426]\n",
      "[0.66693795]\n",
      "[0.6298999]\n",
      "[0.61427355]\n",
      "[0.66728604]\n",
      "[0.6645416]\n",
      "[0.60720515]\n",
      "[0.6554912]\n",
      "[0.7099365]\n",
      "[0.6690541]\n",
      "[0.63489467]\n",
      "[0.6006347]\n",
      "[0.63027996]\n",
      "[0.65198153]\n",
      "[0.66819173]\n",
      "[0.6984992]\n",
      "[0.6388181]\n",
      "[0.63802844]\n",
      "[0.6579354]\n",
      "[0.6465504]\n",
      "[0.6243863]\n",
      "[0.6112146]\n",
      "[0.6438794]\n",
      "[0.65511954]\n",
      "[0.6375542]\n",
      "[0.6217649]\n",
      "[0.6409212]\n",
      "[0.63267744]\n",
      "[0.67168856]\n",
      "[0.6559849]\n",
      "[0.5904107]\n",
      "[0.58961093]\n",
      "[0.60953116]\n",
      "[0.6018254]\n",
      "[0.62829]\n",
      "[0.63386595]\n",
      "[0.6559038]\n",
      "[0.63165855]\n",
      "[0.57865083]\n",
      "[0.6367177]\n",
      "[0.6275382]\n",
      "[0.6013943]\n",
      "[0.61832964]\n",
      "[0.5814745]\n",
      "[0.6130593]\n",
      "[0.61607367]\n",
      "[0.61617714]\n",
      "[0.6189126]\n",
      "[0.6004429]\n",
      "[0.6141848]\n",
      "[0.6078212]\n",
      "[0.59658414]\n",
      "[0.57881284]\n",
      "[0.6219481]\n",
      "[0.64322424]\n",
      "[0.6189308]\n",
      "[0.62820005]\n",
      "[0.63080716]\n",
      "[0.63733387]\n",
      "[0.6067828]\n",
      "[0.6345937]\n",
      "[0.60718036]\n",
      "[0.5955383]\n",
      "[0.6188577]\n",
      "[0.6559206]\n",
      "[0.5878848]\n",
      "[0.62391365]\n",
      "[0.5956735]\n",
      "[0.57873327]\n",
      "[0.5951497]\n",
      "[0.62453413]\n",
      "[0.6319319]\n",
      "[0.57703906]\n",
      "[0.6198065]\n",
      "[0.61876345]\n",
      "[0.598046]\n",
      "[0.5927633]\n",
      "[0.6108854]\n",
      "[0.6370481]\n",
      "[0.60642457]\n",
      "[0.622981]\n",
      "[0.6649636]\n",
      "[0.6043812]\n",
      "[0.616415]\n",
      "[0.63710755]\n",
      "[0.62051505]\n",
      "[0.6470666]\n",
      "[0.6123853]\n",
      "[0.6347168]\n",
      "[0.60964894]\n",
      "[0.61782694]\n",
      "[0.6084706]\n",
      "[0.601339]\n",
      "[0.5982485]\n",
      "[0.63611215]\n",
      "[0.6020974]\n",
      "[0.6453604]\n",
      "[0.6180246]\n",
      "[0.6471224]\n",
      "[0.62420243]\n",
      "[0.6389493]\n",
      "[0.60591775]\n",
      "[0.61014175]\n",
      "[0.594717]\n",
      "[0.57064736]\n",
      "[0.6029171]\n",
      "[0.6116824]\n",
      "[0.6089461]\n",
      "[0.62455124]\n",
      "[0.5793476]\n",
      "[0.630307]\n",
      "[0.56605715]\n",
      "[0.58895254]\n",
      "[0.60082066]\n",
      "[0.6611967]\n",
      "[0.6082836]\n",
      "[0.6420213]\n",
      "[0.6133492]\n",
      "[0.6157196]\n",
      "[0.63074726]\n",
      "[0.6247493]\n",
      "[0.6368897]\n",
      "[0.6281205]\n",
      "[0.6481104]\n",
      "[0.6383796]\n",
      "[0.5875419]\n",
      "[0.6700201]\n",
      "[0.64863926]\n",
      "[0.6411253]\n",
      "[0.6880845]\n",
      "[0.62540925]\n",
      "[0.6050751]\n",
      "[0.6099444]\n",
      "[0.5799332]\n",
      "[0.6038054]\n",
      "[0.6430048]\n",
      "[0.63152605]\n",
      "[0.6676624]\n",
      "[0.6218053]\n",
      "[0.6388992]\n",
      "[0.6506995]\n",
      "[0.6635791]\n",
      "[0.5890684]\n",
      "[0.620581]\n",
      "[0.66637456]\n",
      "[0.7118845]\n",
      "[0.5849039]\n",
      "[0.6254246]\n",
      "[0.55436265]\n",
      "[0.6083028]\n",
      "[0.6461188]\n",
      "[0.6595668]\n",
      "[0.6267488]\n",
      "[0.6326039]\n",
      "[0.65021473]\n",
      "[0.62898666]\n",
      "[0.6114817]\n",
      "[0.58424836]\n",
      "[0.69021857]\n",
      "[0.5865336]\n",
      "[0.6098128]\n",
      "[0.62755406]\n",
      "[0.59856284]\n",
      "[0.6446778]\n",
      "[0.58644295]\n",
      "[0.6319982]\n",
      "[0.6087886]\n",
      "[0.5902849]\n",
      "[0.66100115]\n",
      "[0.6006365]\n",
      "[0.5975665]\n",
      "[0.66925734]\n",
      "[0.6653401]\n",
      "[0.6296874]\n",
      "[0.64936465]\n",
      "[0.6523724]\n",
      "[0.67829376]\n",
      "[0.6331628]\n",
      "[0.6128307]\n",
      "[0.6006596]\n",
      "[0.661811]\n",
      "[0.6161158]\n",
      "[0.61905897]\n",
      "[0.6382167]\n",
      "[0.6846448]\n",
      "[0.62712795]\n",
      "[0.57588744]\n",
      "[0.60707545]\n",
      "[0.588617]\n",
      "[0.64097273]\n",
      "[0.65457934]\n",
      "[0.63394845]\n",
      "[0.5440005]\n",
      "[0.59154737]\n",
      "[0.639526]\n",
      "[0.59500426]\n",
      "[0.5895181]\n",
      "[0.5873164]\n",
      "[0.6387671]\n",
      "[0.64431846]\n",
      "[0.6163869]\n",
      "[0.6417701]\n",
      "[0.6175598]\n",
      "[0.64265895]\n",
      "[0.68625724]\n",
      "[0.61696154]\n",
      "[0.58823115]\n",
      "[0.579551]\n",
      "[0.6380218]\n",
      "[0.6451229]\n",
      "[0.618876]\n",
      "[0.6161207]\n",
      "[0.6665578]\n",
      "[0.61388934]\n",
      "[0.6234844]\n",
      "[0.62577695]\n",
      "[0.62359124]\n",
      "[0.62068325]\n",
      "[0.6306673]\n",
      "[0.6747866]\n",
      "[0.6999451]\n",
      "[0.67136765]\n",
      "[0.6353898]\n",
      "[0.5918956]\n",
      "[0.68781376]\n",
      "[0.555787]\n",
      "[0.6523757]\n",
      "[0.6422209]\n",
      "[0.58992624]\n",
      "[0.6421187]\n",
      "[0.6316196]\n",
      "[0.64254117]\n",
      "[0.6668116]\n",
      "[0.5762599]\n",
      "[0.6526414]\n",
      "[0.6392248]\n",
      "[0.62886333]\n",
      "[0.62306285]\n",
      "[0.6454356]\n",
      "[0.6234041]\n",
      "[0.6317836]\n",
      "[0.62760913]\n",
      "[0.6308571]\n",
      "[0.62180537]\n",
      "[0.6519574]\n",
      "[0.61377853]\n",
      "[0.62877214]\n",
      "[0.5898254]\n",
      "[0.6283759]\n",
      "[0.6606133]\n",
      "[0.6113862]\n",
      "[0.6403747]\n",
      "[0.6305274]\n",
      "[0.6159693]\n",
      "[0.63994306]\n",
      "[0.6534295]\n",
      "[0.64073783]\n",
      "[0.6709477]\n",
      "[0.6887503]\n",
      "[0.6870711]\n",
      "[0.6231843]\n",
      "[0.6389921]\n",
      "[0.64436734]\n",
      "[0.6926328]\n",
      "[0.6544444]\n",
      "[0.6477175]\n",
      "[0.6517968]\n",
      "[0.56873417]\n",
      "[0.62285244]\n",
      "[0.59936124]\n",
      "[0.6050918]\n",
      "[0.60687226]\n",
      "[0.66142154]\n",
      "[0.6631132]\n",
      "[0.6259446]\n",
      "[0.6500194]\n",
      "[0.65215695]\n",
      "[0.6714443]\n",
      "[0.6119397]\n",
      "[0.6843952]\n",
      "[0.600174]\n",
      "[0.6351993]\n",
      "[0.66539985]\n",
      "[0.69149065]\n",
      "[0.6773821]\n",
      "[0.6778656]\n",
      "[0.6786029]\n",
      "[0.67064977]\n",
      "[0.583151]\n",
      "[0.6551455]\n",
      "[0.6727328]\n",
      "[0.66822666]\n",
      "[0.62665975]\n",
      "[0.6617225]\n",
      "[0.65805453]\n",
      "[0.63490736]\n",
      "[0.6670846]\n",
      "[0.6462664]\n",
      "[0.5986699]\n",
      "[0.6038305]\n",
      "[0.6516303]\n",
      "[0.66578674]\n",
      "[0.64359426]\n",
      "[0.64930737]\n",
      "[0.669377]\n",
      "[0.6970184]\n",
      "[0.6152344]\n",
      "[0.627886]\n",
      "[0.67953014]\n",
      "[0.692435]\n",
      "[0.63501483]\n",
      "[0.73242396]\n",
      "[0.6971121]\n",
      "[0.71783715]\n",
      "[0.63818985]\n",
      "[0.6754917]\n",
      "[0.6277535]\n",
      "[0.67301744]\n",
      "[0.6915219]\n",
      "[0.66114074]\n",
      "[0.65214527]\n",
      "[0.6402457]\n",
      "[0.6901272]\n",
      "[0.6553399]\n",
      "[0.6478308]\n",
      "[0.6761765]\n",
      "[0.6227296]\n",
      "[0.650968]\n",
      "[0.6167148]\n",
      "[0.64662874]\n",
      "[0.6444301]\n",
      "[0.63208425]\n",
      "[0.67020637]\n",
      "[0.6493064]\n",
      "[0.65936387]\n",
      "[0.6275187]\n",
      "[0.6920709]\n",
      "[0.6438383]\n",
      "[0.6010065]\n",
      "[0.6125769]\n",
      "[0.5696933]\n",
      "[0.67632025]\n",
      "[0.6159549]\n",
      "[0.598345]\n",
      "[0.6923785]\n",
      "[0.62999713]\n",
      "[0.6481998]\n",
      "[0.58941174]\n",
      "[0.6733057]\n",
      "[0.6664414]\n",
      "[0.6871307]\n",
      "[0.67975783]\n",
      "[0.65649694]\n",
      "[0.6480275]\n",
      "[0.6378627]\n",
      "[0.66145945]\n",
      "[0.6795826]\n",
      "[0.68359923]\n",
      "[0.6872066]\n",
      "[0.5634031]\n",
      "[0.66227174]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(newNPX_v)\n",
    "for each in result:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7019565217909605"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
